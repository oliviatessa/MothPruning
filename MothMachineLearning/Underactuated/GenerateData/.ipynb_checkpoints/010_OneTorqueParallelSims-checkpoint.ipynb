{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callin Switzer\n",
    "### 16 Jan 2020\n",
    "### Simulate data for training neural network \n",
    "### This uses the \"one torque\" or  the \"underactuated\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \n",
      "[GCC 7.2.0]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import simUtils_one_torque # note that this is a custom-written file \n",
    "import importlib\n",
    "import functools\n",
    "import sqlite3\n",
    "from collections import OrderedDict\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last run on 2022-04-12 21:49:00.979646\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "#pythonMadeData = r\"D:/Dropbox/AcademiaDropbox/mothMachineLearning_dataAndFigs/PythonGeneratedData_oneTorque\"\n",
    "#databaseFileName = \"onetorqueDataV3.db\"\n",
    "\n",
    "pythonMadeData = '/home/olivia/mothPruning/MothSimulations/'\n",
    "databaseFileName = 'mothData_s_1_3.db'\n",
    "\n",
    "if not os.path.exists(pythonMadeData):\n",
    "    os.mkdir(pythonMadeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "_ = importlib.reload(simUtils_one_torque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1.3 #scaling for extrapolation experiments\n",
    "\n",
    "# save global options\n",
    "globalDict = OrderedDict({\n",
    "            \"bhead\": s * 0.5,\n",
    "            \"ahead\": s * 0.9,\n",
    "            \"bbutt\": s * 0.75,\n",
    "            \"abutt\": s * 1.9, \n",
    "            \"rho_head\": 0.9,\n",
    "            \"rho_butt\": 0.4,\n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": s * 0.9, \n",
    "            \"L2\": s * 1.9,  \n",
    "            \"L3\": s * 0.75,\n",
    "            \"K\": 23000,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 2, # return start and endpoints\n",
    "            \"nrun\" : 10000000 # (max) number of  trajectories.\n",
    "            })\n",
    "\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho_head']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho_butt\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.02, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]\n",
    "\n",
    "\n",
    "# ranges for control variables\n",
    "rangeDict = {\"Fmin\": 0,\n",
    "             \"Fmax\": 44300,\n",
    "             \"alphaMin\":  0,\n",
    "             \"alphaMax\":2*np.pi, \n",
    "             \"tau0Min\": -100000, \n",
    "             \"tau0Max\": 100000}\n",
    "\n",
    "# ranges for controls \n",
    "ranges = np.array([[rangeDict[\"Fmin\"], rangeDict[\"Fmax\"]], \n",
    "                   [rangeDict[\"alphaMin\"], rangeDict[\"alphaMax\"]], \n",
    "                   [rangeDict[\"tau0Min\"], rangeDict[\"tau0Max\"] ]])\n",
    "\n",
    "# ranges for initial conditions\n",
    "IC_ranges = np.array([[0, 0],        #x\n",
    "                      [-1500, 1500], #xdot  \n",
    "                      [0, 0],        #y\n",
    "                      [-1500, 1500], #ydot\n",
    "                      [0, 2*np.pi],  #theta\n",
    "                      [-25, 25],     #theta dot\n",
    "                      [0, 2*np.pi],  #phi\n",
    "                      [-25, 25]])    # phi dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(dataType, nrun):\n",
    "    '''\n",
    "    Generate training data\n",
    "    \n",
    "    Params:\n",
    "        dataType (str): a label for the data - \"trainingData_\" or \n",
    "                        \"testingData\"\n",
    "        nrun (int): number of runs of the for-loop.\n",
    "    '''\n",
    "    \n",
    "    for ii in np.arange(0,nrun): \n",
    "        print(ii)\n",
    "\n",
    "        # generate random ICs and controls\n",
    "        # random F, alpha, tau\n",
    "        FAlphaTau_list = np.random.uniform(ranges[:, 0], ranges[:, 1], \n",
    "                                           size=(globalDict[\"nrun\"], ranges.shape[0]))\n",
    "\n",
    "        # random initial conditions for state 0\n",
    "        state0_ICs = np.random.uniform(IC_ranges[:, 0], IC_ranges[:, 1], size=(globalDict[\"nrun\"], IC_ranges.shape[0]))\n",
    "\n",
    "        # run simulations in parallel, \"nrun\"s at a time\n",
    "        p = Pool(cpu_count() - 2)\n",
    "        stt = time.time()\n",
    "        bb = p.map(functools.partial(simUtils_one_torque.flyBug_listInput_oneTorque, t=t, \n",
    "                                      state0_ICs = state0_ICs, \n",
    "                                      FAlphaTau_list= FAlphaTau_list, \n",
    "                                      globalList = globalList), range(globalDict[\"nrun\"]))\n",
    "        print(\"time for one run:\", time.time() - stt)\n",
    "        p.close()\n",
    "        p.join()\n",
    "\n",
    "        # reshape to put into a pd data frame\n",
    "        bb2 = np.array(bb).reshape(globalDict[\"nrun\"], -1, order = \"F\")\n",
    "        bb3 = np.hstack([bb2, FAlphaTau_list])\n",
    "\n",
    "        simDF = pd.DataFrame(bb3, columns =  [\"x_0\", \"xd_0\",\"y_0\",\"yd_0\",\n",
    "                                             \"theta_0\",\"thetad_0\",\"phi_0\",\"phid_0\", \n",
    "                                             \"x_f\", \"xd_f\",\"y_f\",\"yd_f\",\n",
    "                                             \"theta_f\",\"thetad_f\",\"phi_f\",\"phid_f\", \n",
    "                                                  \"F\", \"alpha\", \"tau0\"])\n",
    "\n",
    "        # write to database, \n",
    "        # makes a new database if it doesn't already exist\n",
    "        con1 = sqlite3.connect(os.path.join(pythonMadeData, databaseFileName))\n",
    "\n",
    "        # get table names from database\n",
    "        try:\n",
    "            cursorObj = con1.cursor()\n",
    "            cursorObj.execute('SELECT name from sqlite_master where type= \"table\"')\n",
    "            tableNames = cursorObj.fetchall()\n",
    "            cursorObj.close()\n",
    "        except:\n",
    "            print(\"can't get table names\")\n",
    "\n",
    "        simDF.to_sql(dataType + str(len(tableNames)).zfill(2), con1, if_exists = \"fail\", index = False)\n",
    "\n",
    "        # close connection\n",
    "        con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one run: 1059.4752888679504\n"
     ]
    }
   ],
   "source": [
    "# generate training data\n",
    "dataType = \"trainingData_\"\n",
    "generateData(dataType, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/olivia/anaconda3/envs/deepLearn_V4/lib/python3.6/site-packages/scipy/integrate/odepack.py:236: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one run: 33503.083455085754\n"
     ]
    }
   ],
   "source": [
    "dataType = \"testingData_\"\n",
    "generateData(dataType, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainingData_00', 'testingData_01']\n"
     ]
    }
   ],
   "source": [
    "# get table names in database\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, databaseFileName))\n",
    "cursorObj = con1.cursor()\n",
    "res = cursorObj.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tableNames = [name[0] for name in res]\n",
    "con1.close()\n",
    "print(tableNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE test AS SELECT * FROM testingData_01\n"
     ]
    }
   ],
   "source": [
    " # Combine testing Data into a single Table\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, databaseFileName))\n",
    "con1.execute(\"DROP TABLE IF EXISTS test\")\n",
    "sqlStatement = \"CREATE TABLE test AS \" + \" UNION ALL \".join([\"SELECT * FROM \" + tableNames[ii] for ii in range(len(tableNames)) if tableNames[ii].startswith(\"testingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.execute(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE train AS SELECT * FROM trainingData_00\n"
     ]
    }
   ],
   "source": [
    "# Combine Training Data into a single Table\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, databaseFileName))\n",
    "con1.execute(\"DROP TABLE IF EXISTS train\")\n",
    "sqlStatement = \"CREATE TABLE train AS \" + \" UNION ALL \".join([\"SELECT * FROM \" + tableNames[ii] for ii in range(len(tableNames)) if tableNames[ii].startswith(\"trainingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.execute(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows: 10000000\n",
      "\n",
      "Total rows: 10000000\n"
     ]
    }
   ],
   "source": [
    "# print print the max row number\n",
    "def largestRowNumber(cursor, table_name, print_out=False):\n",
    "    \"\"\" Returns the total number of rows in the database \"\"\"\n",
    "    cursor.execute(\"SELECT max(rowid) from  {}\".format(table_name))\n",
    "    n = cursor.fetchone()[0]\n",
    "    if print_out:\n",
    "        print('\\nTotal rows: {}'.format(n))\n",
    "    return(n)\n",
    "\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, databaseFileName))\n",
    "cursorObj = con1.cursor()\n",
    "largestRowNumber(cursorObj, \"train\", print_out=True)\n",
    "largestRowNumber(cursorObj, \"test\", print_out=True)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS trainingData_00; \n"
     ]
    }
   ],
   "source": [
    "# drop intermediate, smaller training datasets\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, databaseFileName))\n",
    "sqlStatement = \"\".join([\"DROP TABLE IF EXISTS \" + tableNames[ii] + \"; \" for ii in range(len(tableNames)) if tableNames[ii].startswith(\"trainingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.executescript(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS testingData_01; \n"
     ]
    }
   ],
   "source": [
    "# drop intermediate, smaller testing datasets\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, databaseFileName))\n",
    "sqlStatement = \"\".join([\"DROP TABLE IF EXISTS \" + tableNames[ii] + \"; \" for ii in range(len(tableNames)) if tableNames[ii].startswith(\"testingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.executescript(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# get table names in database\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, databaseFileName))\n",
    "cursorObj = con1.cursor()\n",
    "res = cursorObj.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tableNames = [name[0] for name in res]\n",
    "con1.close()\n",
    "print(tableNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "deepLearn_V4",
   "language": "python",
   "name": "deeplearn_v4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
