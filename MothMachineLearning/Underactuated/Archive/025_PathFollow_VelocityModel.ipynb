{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 30 May 2019\n",
    "\n",
    "\n",
    "# Make videos of tracking moth"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Outline:\n",
    "** show how well moth can follow trajectory with network\n",
    "** make function to predict with nnet and then evaluate immediately with ODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
      "last run on 2019-07-17 09:39:10.609007\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.patches import Arc\n",
    "from collections import OrderedDict\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import pandas as pd\n",
    "import importlib\n",
    "print(sys.version)\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.36.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba\n",
    "numba.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simUtils_DLVersion as simUtils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'simUtils_DLVersion' from 'C:\\\\Users\\\\calli\\\\Documents\\\\GitRepos\\\\MothMachineLearning\\\\simUtils_DLVersion.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(simUtils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "tensorflow using CPU\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-07-17 09:39:24.184880\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as colors\n",
    "from  mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "\n",
    "# make sure Keras uses CPU instead of GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "else: \n",
    "    print(\"tensorflow using CPU\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "randomRawData = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\PythonGeneratedData\\TrainingData'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def pol2cart(rho, phi):\n",
    "    '''\n",
    "    rho: radius\n",
    "    phi: angle (in radians)\n",
    "    '''\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return ((p1[0]+p2[0])/2, (p1[1]+p2[1])/2)\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.000001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 30,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.02, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0001, 0.0, 0.0001, 3.141592653589793, 0.0001, 0.0, 0.0001]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "state0_ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 0\n",
    "alpha = np.pi/2\n",
    "tau0 = 20\n",
    "tau_w = 2001\n",
    "\n",
    "FAlphaTau_list = [F, alpha, tau0, tau_w]\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>xd</th>\n",
       "      <th>y</th>\n",
       "      <th>yd</th>\n",
       "      <th>theta</th>\n",
       "      <th>thetad</th>\n",
       "      <th>phi</th>\n",
       "      <th>phid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.895929e-08</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.681961</td>\n",
       "      <td>3.141588</td>\n",
       "      <td>-0.006320</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.005338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.379059e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>-1.357820</td>\n",
       "      <td>3.141584</td>\n",
       "      <td>-0.006318</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.005340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.068399e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.002110</td>\n",
       "      <td>-2.033677</td>\n",
       "      <td>3.141580</td>\n",
       "      <td>-0.006315</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.757612e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>-2.709530</td>\n",
       "      <td>3.141575</td>\n",
       "      <td>-0.006311</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.005346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x      xd         y        yd     theta    thetad       phi  \\\n",
       "0  0.000000e+00  0.0001  0.000000  0.000100  3.141593  0.000100  0.000000   \n",
       "1  6.895929e-08  0.0001 -0.000237 -0.681961  3.141588 -0.006320  0.000004   \n",
       "2  1.379059e-07  0.0001 -0.000941 -1.357820  3.141584 -0.006318  0.000007   \n",
       "3  2.068399e-07  0.0001 -0.002110 -2.033677  3.141580 -0.006315  0.000011   \n",
       "4  2.757612e-07  0.0001 -0.003746 -2.709530  3.141575 -0.006311  0.000015   \n",
       "\n",
       "       phid  \n",
       "0  0.000100  \n",
       "1  0.005338  \n",
       "2  0.005340  \n",
       "3  0.005342  \n",
       "4  0.005346  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tragDF = pd.DataFrame([x, xd, y, yd, theta, thetad, phi, phid]).transpose()\n",
    "tragDF.columns = \"x, xd, y, yd, theta, thetad, phi, phid\".split(\", \")\n",
    "tragDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b1531bdbe0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b152dfc2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tragDF.plot(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot moth at certain timesteps\n",
    "# plot final positions\n",
    "def plotMoth(x,y,theta, phi, F, alpha, tau0, fig, ax):\n",
    "    # plot moth and force\n",
    "\n",
    "    thoraxLen = 0.908 * 2# cm\n",
    "    abLen = 1.747 *2 #cm\n",
    "    bodyWidth = 1.1\n",
    "\n",
    "\n",
    "    # plot trajectory\n",
    "    #fig, ax = plt.subplots( figsize = [10,10])\n",
    "    ax.set_aspect('equal', 'datalim')\n",
    "    #ax.plot(x,y, label = 'trajectory x vs y')\n",
    "\n",
    "    center = np.array([x, y])\n",
    "    head = center + np.array(pol2cart(thoraxLen, theta))\n",
    "    abTip = center + np.array(pol2cart(abLen, phi))\n",
    "\n",
    "\n",
    "\n",
    "    xx, yy = zip(*[center, head])\n",
    "    xab,yab = zip(*[center, abTip])\n",
    "\n",
    "    el = Ellipse(midpoint(center, head), width = thoraxLen, height = bodyWidth, facecolor='#907760', alpha=0.9, angle = math.degrees(theta))\n",
    "    el2 = Ellipse(midpoint(center, abTip), width = abLen, height = bodyWidth, facecolor='#DEC9B0', alpha=0.9, angle = math.degrees(phi))\n",
    "    \n",
    "#     torqueArc = Arc([x,y], 1, 1, angle=0.0, theta1= np.degrees(theta), theta2=np.degrees(phi), color = \"#B61212\")\n",
    "    \n",
    "    \n",
    "    ax.add_artist(el)\n",
    "    ax.add_artist(el2)\n",
    "#     ax.add_artist(torqueArc)\n",
    "    \n",
    "#     # add torque arrow\n",
    "#     ax.arrow(x = x + 1, y = forceCenter[1], \n",
    "#              dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "#             head_width = 0.2, color = \"#B61212\")\n",
    "\n",
    "\n",
    "\n",
    "    ax.plot(xx, yy, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xx, yy, s= 10, c = 'k', alpha = 0.2)\n",
    "    ax.plot(xab,yab, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xab,yab, s = 10, c = 'k', alpha = 0.2)\n",
    "\n",
    "    # plot force \n",
    "    forceAlpha = alpha\n",
    "    forceCenter = midpoint(center, head)\n",
    "    forceMagnitude = F / 15000 # scale \n",
    "    forceAngle = theta + forceAlpha\n",
    "    forceTip = np.add(pol2cart(forceMagnitude, forceAngle), forceCenter)\n",
    "    ax.arrow(x = forceCenter[0], y = forceCenter[1], \n",
    "             dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "            head_width = 0.2, color = \"#B61212\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tmp dir for images\n",
    "tmpDir2 = os.path.join(r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs', \"MothVid_Velocity_big\")\n",
    "if not os.path.exists(tmpDir2):\n",
    "    os.mkdir(tmpDir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize = [10,10])\n",
    "# plt.axes().set_aspect('equal', 'datalim')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "maxFrms = len(x)\n",
    "\n",
    "xlim = [np.min(x[0:maxFrms+1])-5, np.max(x[0:maxFrms+1])+5]\n",
    "ylim =[np.min(y[0:maxFrms+1])-5, np.max(y[0:maxFrms+1])+5]\n",
    "xrng = np.diff(xlim)\n",
    "yrng = np.diff(ylim)\n",
    "maxrng = np.max([xrng, yrng])\n",
    "newxlim = [np.sum(xlim)/2 - maxrng /2, np.sum(xlim)/2 + maxrng /2]\n",
    "newylim = [np.sum(ylim)/2 - maxrng /2, np.sum(ylim)/2 + maxrng /2 ]\n",
    "\n",
    "\n",
    "for ii in np.arange(1, maxFrms, 1):\n",
    "    fig, ax = plt.subplots( figsize = [10,10])\n",
    "\n",
    "    plt.plot(x[0:ii+1], y[0:ii+1], c= 'orange', label = \"Python\")\n",
    "    plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "    \n",
    "\n",
    "    ax.set_ylim(newylim)\n",
    "    ax.set_xlim(newxlim)\n",
    "    ax.set_ylabel(\"vertical position (cm)\")\n",
    "    ax.set_xlabel(\"horizontal position (cm)\")\n",
    "    \n",
    "#     # add torque\n",
    "#     if tau0 < 0:\n",
    "#         marker = r'$\\circlearrowleft$'\n",
    "#     else:\n",
    "#         marker = r'$\\circlearrowright$'\n",
    "#     ax.plot(x[ii],y[ii], marker=marker,ms=tau0/100000,  color = \"#B61212\")\n",
    "    fig.savefig(os.path.join(tmpDir2, str(ii).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "    # plt.legend()\n",
    "    plt.close()\n",
    "    if np.mod(ii, 10) == 0:\n",
    "        print(ii)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir2)\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 30 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000001_output_mothPath2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model and scaler\n",
    "modelPath = r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0__Num_512_512_512_16__Wei_0_2019_07_11__07_51_42_velocity.h5\"\n",
    "model = load_model(modelPath)\n",
    "\n",
    "# read in scalers\n",
    "scalerX = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput\\scalerX_veloc2019_07_11__07_51_42.pkl\", \"rb\"))\n",
    "scalerY = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput\\scalerY_veloc2019_07_11__07_51_42.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               5632      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 539,203\n",
      "Trainable params: 539,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REFREF: check model loss\n",
    "\n",
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [\"phi_0\", \"theta_0\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\",\n",
    "                   \"x_99\", \"y_99\", \"phi_99\",  \"theta_99\",\n",
    "                   \"x_dot_99\", \"y_dot_99\",\"phi_dot_99\",\"theta_dot_99\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980102, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980102/1980102 [==============================] - 76s 38us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0012489242974622523, 0.0012489242974622523]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate F and alpha from Fx and Fy\n",
    "\n",
    "# calculate alpha\n",
    "def quadrant(Fx, Fy):\n",
    "    if (Fx >= 0) & (Fy >= 0):\n",
    "        q = 1\n",
    "    elif (Fx < 0) & (Fy >= 0):\n",
    "        q = 2\n",
    "    elif (Fx < 0) & (Fy < 0):\n",
    "        q = 3\n",
    "    elif (Fx >= 0) & (Fy < 0):\n",
    "        q = 4\n",
    "    else:\n",
    "        q = 999999\n",
    "    return(q)\n",
    "\n",
    "\n",
    "def angleCalc(Fx, Fy, q):\n",
    "    fx = np.abs(Fx)\n",
    "    fy = np.abs(Fy)\n",
    "    \n",
    "    if q == 1:\n",
    "        alpha = np.arctan(fy/fx)\n",
    "    elif q == 2:\n",
    "        alpha = np.pi - np.arctan(fy/fx)\n",
    "    elif q == 3: \n",
    "        alpha = np.pi + np.arctan(fy/fx)\n",
    "    elif q == 4:\n",
    "        alpha = (2*np.pi) - np.arctan(fy/fx)\n",
    "    return(alpha)\n",
    "\n",
    "def F_alpha_calc (Fx, Fy):\n",
    "    q = quadrant(Fx, Fy)\n",
    "    alpha = angleCalc(Fx, Fy, q)\n",
    "    F = np.sqrt(Fx**2 + Fy**2)\n",
    "    return(F, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputData = # make dataset\n",
    "Xcols = ['phi_0', 'theta_0', 'x_dot_0', 'y_dot_0', 'phi_dot_0', 'theta_dot_0',\n",
    "       'x_dot_99', 'y_dot_99', 'phi_dot_99', 'theta_dot_99']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref calculate new x and y from error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "overallCtr = 1\n",
    "\n",
    "\n",
    "# refref: maybe the derivatives should be in the input, so it doesn't go too fast\n",
    "\n",
    "# define initial position and goal position\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "where_I_am = OrderedDict({\n",
    "                        \"x_0\": [0], \n",
    "                        \"x_dot_0\":[-0.0001], \n",
    "                        \"y_0\":[0], \n",
    "                        \"y_dot_0\": [-0.0001]  ,\n",
    "                        \"theta_0\": [np.pi/2]  ,\n",
    "                        \"theta_dot_0\": [-0.0001]  , \n",
    "                        \"phi_0\": [3*np.pi/2]   ,\n",
    "                        \"phi_dot_0\":[-0.0001] })\n",
    "\n",
    "\n",
    "where_I_want2b = OrderedDict({\"x_99\": [0],\n",
    "                              \"y_99\": [0],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2], \n",
    "                             \"x_dot_99\": [-0.00001], \n",
    "                             \"y_dot_99\": [-0.00001], \n",
    "                             \"x_dot_99\": [-0.00001], \n",
    "                              \"theta_dot_99\": [-0.00001], \n",
    "                             \"phi_dot_99\": [-0.00001]})\n",
    "\n",
    "xList = []\n",
    "yList = []\n",
    "\n",
    "prevXY = [where_I_am[\"x_0\"][0], where_I_am[\"y_0\"][0]]\n",
    "\n",
    "goalXY = [where_I_want2b[\"x_99\"][0], where_I_want2b[\"y_99\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b104c769b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "# don't pay attention to F, alpha, tau0\n",
    "plotMoth(where_I_am[\"x_0\"][0],where_I_am[\"y_0\"][0],where_I_am[\"theta_0\"][0], where_I_am[\"phi_0\"][0], F, alpha, tau0, fig, ax)\n",
    "plotMoth(where_I_want2b[\"x_99\"][0],\n",
    "         where_I_want2b[\"y_99\"][0],\n",
    "         where_I_want2b[\"theta_99\"][0],\n",
    "         where_I_want2b[\"phi_99\"][0], F, alpha, tau0, fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData =  pd.DataFrame(OrderedDict(list(where_I_am.items()) + list(where_I_want2b.items())))\n",
    "inputData = inputData.loc[:, Xcols]\n",
    "#print(inputData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10741.79296875, -17266.484375  , -13607.95214844], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict force needed to attain \n",
    "## scale data and transform\n",
    "X_scaled = scalerX.transform(inputData)\n",
    "\n",
    "\n",
    "## predict with nnet\n",
    "pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "# inverse transform\n",
    "pred_trans = scalerY.inverse_transform(pred)\n",
    "\n",
    "pred_trans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\AcademiaDropbox\\\\mothMachineLearning_dataAndFigs\\\\Figs\\\\MothVid_Velocity_big'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpDir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 0\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 1\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 2\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 3\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 4\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 5\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 6\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 7\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 8\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 9\n"
     ]
    }
   ],
   "source": [
    "###### start of loop\n",
    "##### hybrid approach\n",
    "\n",
    "\n",
    "for jj in range(10):\n",
    "\n",
    "    inputData =  pd.DataFrame(OrderedDict(list(where_I_am.items()) + list(where_I_want2b.items())))\n",
    "    inputData = inputData.loc[:, Xcols]\n",
    "\n",
    "\n",
    "    # predict force needed to attain \n",
    "    ## scale data and transform\n",
    "    X_scaled = scalerX.transform(inputData)\n",
    "    \n",
    "    \n",
    "    ## predict with nnet\n",
    "    pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "    # inverse transform\n",
    "    pred_trans = scalerY.inverse_transform(pred)\n",
    "    Fx, Fy, tau0  = pred_trans[0]\n",
    "\n",
    "    # convert FX, Fy, back to F, alpha\n",
    "    # F, alpha = cart2pol(Fx, Fy)\n",
    "    F, alpha = F_alpha_calc(Fx, Fy)\n",
    "\n",
    "\n",
    "    # plug predictions into simulation\n",
    "    FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    state0_ICs = [ v[0] for v in where_I_am.values() ]\n",
    "\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    # add previous position to x and y\n",
    "    x = x + prevXY[0]\n",
    "    y = y + prevXY[1]\n",
    "    \n",
    "    # plot actual position\n",
    "    xList.extend(x.tolist())\n",
    "    yList.extend(y.tolist())\n",
    "\n",
    "\n",
    "\n",
    "    maxFrms = len(x)\n",
    "\n",
    "\n",
    "\n",
    "    # refref: add x's to each plot\n",
    "    for ii in np.arange(0, maxFrms, 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.plot(xList[:-(maxFrms-ii)], yList[:-(maxFrms-ii)], c= 'orange', label = \"moth trajectory\", alpha = 0.3)\n",
    "        #plt.plot(where_I_want2b[\"x_99\"], where_I_want2b[\"y_99\"], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plt.plot(goalXY[0], goalXY[1], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "#         ax.set_ylim([-30, 30])\n",
    "#         ax.set_xlim([-30, 30])\n",
    "        ax.set_ylim([-80, 80])\n",
    "        ax.set_xlim([-80, 80])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir2, str(overallCtr).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        #plt.show()\n",
    "        overallCtr += 1\n",
    "\n",
    "\n",
    "        plt.close()\n",
    "        if np.mod(ii, 3) == 0:\n",
    "            print(ii)\n",
    "\n",
    "\n",
    "\n",
    "    # calculate error and compute new initial position, but keep goal position the same\n",
    "\n",
    "    ### REFREF: may be calculating this incorrectly\n",
    "    ### where I am should always start at x_0, y_0 == (0, 0)\n",
    "    ### where I want to be should be the error....\n",
    "    \n",
    "    # update prevXY\n",
    "    prevXY = [x[-1], y[-1]]\n",
    "    \n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    where_I_am2 = OrderedDict({\n",
    "                            \"x_0\": [0], \n",
    "                            \"x_dot_0\":[xd[-1]], \n",
    "                            \"y_0\":[0], \n",
    "                            \"y_dot_0\": [yd[-1]]  ,\n",
    "                            \"theta_0\": [theta[-1]]  ,\n",
    "                            \"theta_dot_0\": [thetad[-1]] , \n",
    "                            \"phi_0\": [phi[-1]]   ,\n",
    "                            \"phi_dot_0\":[phid[-1]] })\n",
    "\n",
    "\n",
    "    # calculate true position\n",
    "    actual_whereIam = OrderedDict({\n",
    "                            \"x\": [where_I_want2b[\"x_99\"] + x],\n",
    "                            \"y\":[where_I_want2b[\"x_99\"] + y]})\n",
    "    \n",
    "    # refref: i'm not sure this is right\n",
    "    \n",
    "    where_I_want2b2 = OrderedDict({\"x_99\": [ goalXY[0] - prevXY[0] ],\n",
    "                              \"y_99\": [goalXY[1] - prevXY[1]],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2], \n",
    "                                  \"x_dot_99\": [0.00001], \n",
    "                             \"y_dot_99\": [0.00001], \n",
    "                             \"x_dot_99\": [0.00001], \n",
    "                              \"theta_dot_99\": [0.00001], \n",
    "                             \"phi_dot_99\": [0.00001]})\n",
    "    \n",
    "    \n",
    "    # update whereIam\n",
    "    where_I_am = where_I_am2\n",
    "    where_I_want2b = where_I_want2b2\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"loop\", jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir2)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 60 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_output_mothPath.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "! explorer ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goalXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_want2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: do the same thing with a smaller, pruned network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make vid of multiple moth trajectoies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 40,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.1, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug predictions into simulation\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, alpha, tau0 = (np.random.rand(3)* 1000).tolist()\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi/2 - 0.3,0.0001, -np.pi/2 - 0.3,0.0001]\n",
    "state0_ICs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDir3 = os.path.join(r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019', \"MPC_Example\")\n",
    "if not os.path.exists(tmpDir3):\n",
    "    os.mkdir(tmpDir3)\n",
    "\n",
    "overallCtr2 = 1\n",
    "\n",
    "\n",
    "xlist = []\n",
    "ylist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pathNum in range(20):\n",
    "    F, alpha, tau0 = (np.random.rand(3)* 10000).tolist()\n",
    "    tau0 = tau0*10\n",
    "    FAlphaTau_list = [F, alpha, tau0]\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    xlist.extend(x)\n",
    "    ylist.extend(y)\n",
    "\n",
    "\n",
    "    for ii in np.arange(0, globalDict[\"nstep\"], 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.scatter(xlist[:-(globalDict[\"nstep\"]-ii-1)], ylist[:-(globalDict[\"nstep\"]-ii-1)], c= 'orange', label = \"moth trajectory\", s = 2)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "        ax.set_ylim([-30, 30])\n",
    "        ax.set_xlim([-30, 30])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir3, str(overallCtr2).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        overallCtr2 += 1\n",
    "\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir3)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 30 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2, setpts=0.2*PTS\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_MPCVID.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0\n",
    "xlist[:-(globalDict[\"nstep\"]-ii-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(randomRawData, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: check for repeats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=150, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: start with small network and then build up\n",
    "# refref: start with large network and prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [32, 32, 32, 32], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "\n",
    "# model = load_model(r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0.0__Num_400_400_400_16__Wei_0.0.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [400, 400, 400, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show random weight matrices\n",
    "# show images for matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-5:256//2+5, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RandomWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=15, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1000, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDict[\"mean_squared_error\"].extend(history.history[\"mean_squared_error\"][0:])\n",
    "historyDict[\"val_mean_squared_error\"].extend(history.history[\"val_mean_squared_error\"][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_NOTpruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "# if I need to remake, use this\n",
    "# wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "# wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"TrainedWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refref: plot predictions on test set and make figures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "# apply same transformation to test data\n",
    "# Xtest_scaled = scalerX.transform(Xtest)\n",
    "# Ytest_scaled = scalerY.transform(Ytest)\n",
    "\n",
    "\n",
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "\n",
    "# make data frames\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_c = df_c[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(y_true, y_pred, sample_weight=None, multioutput=uniform_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_notPruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(7):\n",
    "    print (r2_score(df_c.iloc[:,jj ],  df_c.iloc[:,jj+7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START NEW ITEM: train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "#wts =  pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start training\n",
    "# historyDict = {\"mean_squared_error\": [], \n",
    "#                \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start pruning\n",
    "modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numCuts)\n",
    "(50 - cutPercent[numCuts]) * 2 # percent of original network size that is used the pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_Pruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts_pruned.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history_pruned.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numCuts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dictLen).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "#for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "for dictLen in range(300):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(historyDict['mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.plot(range(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "#for dictLen in np.arange(1, 100):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir)\n",
    "\n",
    "os.system('ffmpeg -start_number 0   -r 50 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264 -b:v 10000k  -pix_fmt yuv420p -y  0000000_output_epochs.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frames\n",
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historyDict[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.iloc[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + str(len(historyDict[\"mean_squared_error\"])) +  modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2+1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"Pruned_WeightMatrices\" + str(len(historyDict[\"mean_squared_error\"]))  + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example small network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [20, 20, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])   \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "              \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RondomWTS_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ii in range(100):\n",
    "    \n",
    "        # # fit model without regularization\n",
    "    stt = time.time()\n",
    "    history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                            batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "    winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "    endd = time.time() - stt\n",
    "    print(endd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "    ctr += 1\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWeightImages(model):\n",
    "    \n",
    "     wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWts_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good can I get without trimming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "for ii in np.arange(0, len(wts), 2):\n",
    "    plt.matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot biases\n",
    "\n",
    "for ii in np.arange(1, len(wts), 2):\n",
    "    plt.matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save weights and model\n",
    "model.save(os.path.join(savedModels,  modelName + '_pruned_bias.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_pruned_wts_bias.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,5, figsize=(20, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.2)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "    \n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(5,1, figsize=(30, 10), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(1, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=(30, 10), facecolor='w', edgecolor='k', )\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.1)\n",
    "\n",
    "\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWeightMatrices.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: if whole node is basically 0, then remove the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(wts[2].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(**modelParams)\n",
    "\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model_400Units_newData.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "cutPercent = 49.7\n",
    "for numCuts in range(3):\n",
    "    for numEpocs in range(100):\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 2):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent, 50 + cutPercent), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_and_ODE",
   "language": "python",
   "name": "dl_and_ode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
