{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda custom (64-bit)| (default, Apr 29 2018, 16:14:56) \n",
      "[GCC 7.2.0] \n",
      "\n",
      "last run on 2018-06-08 14:34:04.552300\n"
     ]
    }
   ],
   "source": [
    "# using kernel deepLearn_V2\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetimeL\n",
    "import sys\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "\n",
    "print(sys.version, \"\\n\")\n",
    "\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ubuntu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['DESKTOP_SESSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowsOrMacDirectories():\n",
    "    \"\"\" Sets base directories for win or mac or ubuntu\n",
    "\n",
    "       \n",
    "    \"\"\"\n",
    "    if sys.platform.startswith('linux') or sys.platform.startswith('cygwin'):\n",
    "#         # this excludes your current terminal \"/dev/tty\"\n",
    "        DropboxDirect = os.path.join(\"/hdd12tb/Dropbox\")\n",
    "        dataDir = os.path.join(\"/hdd12tb/MothSimulations/\")\n",
    "    elif os.environ['COMPUTERNAME'] == 'SHEALMACLEARN':\n",
    "        DropboxDirect = os.path.join(\"D:\\Dropbox\")\n",
    "# refref: these are wrong (mac and windows)\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "        DropboxDirect = os.path.join(\"/Users/cswitzer/Dropbox\")\n",
    "    else:\n",
    "        raise EnvironmentError('Unknown computer platform')\n",
    "    \n",
    "    baseDir = os.getcwd()\n",
    "    #dataDir = os.path.join(DropboxDirect, 'mothMachineLearning_dataAndFigs', 'Data')\n",
    "    figDir = os.path.join(DropboxDirect, 'mothMachineLearning_dataAndFigs', 'Figs')\n",
    "    \n",
    "    assert (os.path.isdir(baseDir), \n",
    "            os.path.isdir(dataDir), \n",
    "            os.path.isdir(figDir)) == (True, \n",
    "                                       True, \n",
    "                                       True), \"One or more directories don't exist\"\n",
    "    return baseDir, dataDir, figDir\n",
    "\n",
    "\n",
    "baseDir, dataDir, figDir = windowsOrMacDirectories()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cswitzer/Documents/GitRepos/MothMachineLearning \n",
      " /hdd12tb/MothSimulations/ \n",
      " /hdd12tb/Dropbox/mothMachineLearning_dataAndFigs/Figs\n"
     ]
    }
   ],
   "source": [
    "# define directories\n",
    "print(baseDir, \"\\n\", dataDir, \"\\n\", figDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(os.path.join(dataDir,\"11c-AggressiveManeuver\", \"Qstore\", \"Qstore_1_am_con.mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(os.path.join(dataDir,\"OtherFiles_beforeparallelization\", \"ValSp3_1_am_con.mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "Qmat = scipy.io.loadmat(os.path.join(dataDir,\"11c-AggressiveManeuver\", \"Qstore\", \"Qstore_11_am_ytf.mat\"), squeeze_me=True, struct_as_record=False)\n",
    "#Qmat = scipy.io.loadmat(os.path.join(dataDir,\"11c-AggressiveManeuver\", \"Qstore\", \"Qstore_1_am_con.mat\"))\n",
    "Vmat = scipy.io.loadmat(os.path.join(dataDir,\"OtherFiles_beforeparallelization\", \"ValSp3_1_am_con.mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io as spio\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    def _check_keys(d):\n",
    "        '''\n",
    "        checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        '''\n",
    "        for key in d:\n",
    "            if isinstance(d[key], spio.matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        '''\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        '''\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _tolist(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _tolist(ndarray):\n",
    "        '''\n",
    "        A recursive function which constructs lists from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        '''\n",
    "        elem_list = []\n",
    "        for sub_elem in ndarray:\n",
    "            if isinstance(sub_elem, spio.matlab.mio5_params.mat_struct):\n",
    "                elem_list.append(_todict(sub_elem))\n",
    "            elif isinstance(sub_elem, np.ndarray):\n",
    "                elem_list.append(_tolist(sub_elem))\n",
    "            else:\n",
    "                elem_list.append(sub_elem)\n",
    "        return elem_list\n",
    "    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "qstr = loadmat(os.path.join(dataDir,\"11c-AggressiveManeuver\", \"Qstore\", \"Qstore_11_am_ytf.mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Qstore'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qstr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_finalize__',\n",
       " '__array_interface__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_struct__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'byteswap',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'compress',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'dump',\n",
       " 'dumps',\n",
       " 'fill',\n",
       " 'flags',\n",
       " 'flat',\n",
       " 'flatten',\n",
       " 'getfield',\n",
       " 'imag',\n",
       " 'item',\n",
       " 'itemset',\n",
       " 'itemsize',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'newbyteorder',\n",
       " 'nonzero',\n",
       " 'partition',\n",
       " 'prod',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'setfield',\n",
       " 'setflags',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tobytes',\n",
       " 'tofile',\n",
       " 'tolist',\n",
       " 'tostring',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(qstr[\"Qstore\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F',\n",
       " 'ICs',\n",
       " 'NewICs',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_fieldnames',\n",
       " 'alpha',\n",
       " 'bigQ',\n",
       " 'check',\n",
       " 'cost',\n",
       " 'tau0']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(qstr[\"Qstore\"][0][0]) # gives F, ICs, NewICs, alpha, tau0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qstr[\"Qstore\"][0][0].bigQ.shape # gives x, xdot, y, ydot, theta, thetadot, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-69642.13027859683"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qstr[\"Qstore\"][0][0].tau0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_finalize__',\n",
       " '__array_interface__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_struct__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'byteswap',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'compress',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'dump',\n",
       " 'dumps',\n",
       " 'fill',\n",
       " 'flags',\n",
       " 'flat',\n",
       " 'flatten',\n",
       " 'getfield',\n",
       " 'imag',\n",
       " 'item',\n",
       " 'itemset',\n",
       " 'itemsize',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'newbyteorder',\n",
       " 'nonzero',\n",
       " 'partition',\n",
       " 'prod',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'setfield',\n",
       " 'setflags',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tobytes',\n",
       " 'tofile',\n",
       " 'tolist',\n",
       " 'tostring',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(qstr[\"Qstore\"][0][0].bigQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.23596513e-02, 2.22430811e+00, 7.87845276e-01, 3.95213518e+00,\n",
       "       8.16525851e+00, 2.22368300e+02, 2.97856355e-01, 2.58911053e+00])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qstr[\"Qstore\"][0][0].ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Qstore'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qmat.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdta = Qmat[\"Qstore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<scipy.io.matlab.mio5_params.mat_struct object at 0x7f44237a00b8>,\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qdta[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qdta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'ValSp3'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vmat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20001)\n"
     ]
    }
   ],
   "source": [
    "Qdta = Qmat[\"Qstore\"]\n",
    "dd = pd.DataFrame(Qdta)\n",
    "dd['time'] = np.arange(0, 2, 2.0002e-04)\n",
    "cols = dd.columns.tolist()\n",
    "dd = dd[[cols[-1]] + cols[:-1]] \n",
    "print(dd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['timestep'] = (np.floor(np.arange(0, 100, step = 0.01))).astype(int)\n",
    "cols = dd.columns.tolist()\n",
    "dd = dd[[cols[-1]] + cols[:-1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestep</th>\n",
       "      <th>time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>19990</th>\n",
       "      <th>19991</th>\n",
       "      <th>19992</th>\n",
       "      <th>19993</th>\n",
       "      <th>19994</th>\n",
       "      <th>19995</th>\n",
       "      <th>19996</th>\n",
       "      <th>19997</th>\n",
       "      <th>19998</th>\n",
       "      <th>19999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785398</td>\n",
       "      <td>3.926991</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785398</td>\n",
       "      <td>3.926991</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.785405</td>\n",
       "      <td>3.926991</td>\n",
       "      <td>1.003792</td>\n",
       "      <td>0.422649</td>\n",
       "      <td>0.048971</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>0.027796</td>\n",
       "      <td>4.027603e-07</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>0.785407</td>\n",
       "      <td>3.926990</td>\n",
       "      <td>-0.011122</td>\n",
       "      <td>-1.211176</td>\n",
       "      <td>0.066204</td>\n",
       "      <td>-0.005158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.785416</td>\n",
       "      <td>3.926991</td>\n",
       "      <td>1.983931</td>\n",
       "      <td>0.868754</td>\n",
       "      <td>0.057278</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032963</td>\n",
       "      <td>0.054989</td>\n",
       "      <td>-5.700732e-06</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>0.785423</td>\n",
       "      <td>3.926989</td>\n",
       "      <td>-0.049237</td>\n",
       "      <td>-2.395544</td>\n",
       "      <td>0.085917</td>\n",
       "      <td>-0.007513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.785429</td>\n",
       "      <td>3.926992</td>\n",
       "      <td>2.963612</td>\n",
       "      <td>1.315319</td>\n",
       "      <td>0.064795</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053276</td>\n",
       "      <td>0.082060</td>\n",
       "      <td>-1.955832e-05</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>0.785442</td>\n",
       "      <td>3.926987</td>\n",
       "      <td>-0.087493</td>\n",
       "      <td>-3.579753</td>\n",
       "      <td>0.105314</td>\n",
       "      <td>-0.010017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.785442</td>\n",
       "      <td>3.926994</td>\n",
       "      <td>3.943133</td>\n",
       "      <td>1.762049</td>\n",
       "      <td>0.072037</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073520</td>\n",
       "      <td>0.109017</td>\n",
       "      <td>-4.117008e-05</td>\n",
       "      <td>-0.001935</td>\n",
       "      <td>0.785465</td>\n",
       "      <td>3.926985</td>\n",
       "      <td>-0.126621</td>\n",
       "      <td>-4.763069</td>\n",
       "      <td>0.123132</td>\n",
       "      <td>-0.012591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestep    time         0         1         2         3         4  \\\n",
       "0         0  0.0000  0.000000  0.000000  0.785398  3.926991  0.000100   \n",
       "1         0  0.0002  0.000103  0.000041  0.785405  3.926991  1.003792   \n",
       "2         0  0.0004  0.000405  0.000172  0.785416  3.926991  1.983931   \n",
       "3         0  0.0006  0.000906  0.000393  0.785429  3.926992  2.963612   \n",
       "4         0  0.0008  0.001603  0.000703  0.785442  3.926994  3.943133   \n",
       "\n",
       "          5         6         7    ...        19990     19991         19992  \\\n",
       "0  0.000100  0.000000  0.000000    ...     0.000000  0.000000  0.000000e+00   \n",
       "1  0.422649  0.048971  0.000594    ...     0.012709  0.027796  4.027603e-07   \n",
       "2  0.868754  0.057278  0.003731    ...     0.032963  0.054989 -5.700732e-06   \n",
       "3  1.315319  0.064795  0.006861    ...     0.053276  0.082060 -1.955832e-05   \n",
       "4  1.762049  0.072037  0.009950    ...     0.073520  0.109017 -4.117008e-05   \n",
       "\n",
       "      19993     19994     19995     19996     19997     19998     19999  \n",
       "0  0.000000  0.785398  3.926991  0.000100  0.000100  0.000000  0.000000  \n",
       "1 -0.000124  0.785407  3.926990 -0.011122 -1.211176  0.066204 -0.005158  \n",
       "2 -0.000489  0.785423  3.926989 -0.049237 -2.395544  0.085917 -0.007513  \n",
       "3 -0.001092  0.785442  3.926987 -0.087493 -3.579753  0.105314 -0.010017  \n",
       "4 -0.001935  0.785465  3.926985 -0.126621 -4.763069  0.123132 -0.012591  \n",
       "\n",
       "[5 rows x 20002 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.zeros(Qdta.shape).reshape((-1, 100*8))\n",
    "cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another possible way to rearrange the data\n",
    "stt = time.time()\n",
    "\n",
    "ss = 8 # number of columns to repeat\n",
    "cctr = 0 # output row counter\n",
    "\n",
    "\n",
    "rctr = 0 # row counter for input data\n",
    "    \n",
    "while rctr < Qdta.shape[0]:\n",
    "    \n",
    "    ii = 0 # column counter for input data\n",
    "    while ii < Qdta.shape[1]:\n",
    "        a = np.array(dd.iloc[rctr:(rctr + 100), ii + 2:ii + 2 + ss])\n",
    "        bb = np.array(np.zeros(a.shape)).reshape([1, -1])\n",
    "        bb.shape\n",
    "\n",
    "        for kk in np.arange(0, a.shape[0], step = 1):\n",
    "            bb[0, kk*ss:(kk+1)*ss] = a[kk, 0:ss]  \n",
    "\n",
    "        ii += ss\n",
    "    \n",
    "        cc[cctr, :] = bb\n",
    "        cctr += 1\n",
    "    # update row counter\n",
    "    print(str(cctr) + \" of \" + str(cc.shape[0]))\n",
    "    rctr += 100\n",
    "\n",
    "    \n",
    "print(str(np.round(time.time() - stt)) + \" Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,100))\n",
    "plt.imshow(cc, cmap='hot', interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check\n",
    "for ii in np.arange(5000, 10000):\n",
    "    plt.plot(cc[ii, np.arange(0, 800, step = 8)], cc[ii, np.arange(1, 800, step = 8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frame and name columns\n",
    "tsDf = pd.DataFrame(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsDf[\"timestep\"] = np.floor(np.arange(0,tsDf.shape[0]) / 2500).astype(int)\n",
    "tsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\"x\", \"y\", \"theta\", \"phi\", \"x_dot\", \"y_dot\", \"theta_dot\", \"phi_dot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = 0\n",
    "hh = []\n",
    "for jj in range(100):\n",
    "    hh.append([new_cols[ii] +\"_\" +str(jj) for ii in range(8)])\n",
    "\n",
    "allCols = np.concatenate(hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsDf.columns = np.append(allCols, \"timestep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forceAngle = np.transpose(Vmat[\"ValSp3\"])\n",
    "fa = forceAngle.reshape((250000, 12), order = \"C\" )\n",
    "fa2=  pd.DataFrame(fa)\n",
    "fa2.columns = np.append([new_cols[ii] +\"_\" +str(99) for ii in range(8)], [\"F\", \"alpha\", \"tao\", \"cost\"])\n",
    "fa2[\"Fx\"] = fa2.F * np.cos(fa2.alpha)\n",
    "fa2[\"Fy\"] = fa2.F * np.sin(fa2.alpha)\n",
    "fa2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combDF = pd.merge(tsDf.dropna(), fa2.dropna(), \n",
    "                  left_on = [new_cols[ii] +\"_\" +str(99) for ii in range(8)], \n",
    "                  right_on = [new_cols[ii] +\"_\" +str(99) for ii in range(8)], \n",
    "                  how = \"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how many NA's were dropped\n",
    "fa2.shape[0] - fa2.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finished data munging\n",
    "\n",
    "Now fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combDF.iloc[:, np.concatenate((np.arange(0,8), np.arange(792,800)))].copy()\n",
    "Y = combDF.iloc[:, [803, 805, 806]]\n",
    "\n",
    "# # subtract x_0 and y_0 from everything\n",
    "X.x_99 = X.x_99 - X.x_0\n",
    "X.y_99 = X.y_99 - X.y_0\n",
    "\n",
    "X.x_0 = X.y_0 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scalerX = StandardScaler()  \n",
    "scalerY = StandardScaler()  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(400, activation = \"tanh\", input_dim=Xtrain_scaled.shape[1]))\n",
    "model.add(Dense(400, activation = \"tanh\"))\n",
    "model.add(Dense(16, activation = \"tanh\"))\n",
    "model.add(Dense(16, activation = \"tanh\"))\n",
    "model.add(Dense(Ytrain_scaled.shape[1], activation = \"linear\")) # final layer has 3 outputs\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt = time.time()\n",
    "model.fit(Xtrain_scaled, Ytrain_scaled, epochs=10000, initial_epoch=0, \n",
    "          batch_size = 100000)\n",
    "print(time.time() - stt) # <10 seconds for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpreds = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,3, figsize=(15, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.3)\n",
    "fig.suptitle('Predicted vs. acutal for 4-hidden-layer Neural Network - With Keras', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "nms = [\"tau\", \"Fx\", 'Fy']\n",
    "for ii in range(3):\n",
    "    # read in image\n",
    "    \n",
    "    try:\n",
    "        axs[ii].scatter(y = Ytest_scaled[:,ii],x = nnpreds[:,ii], s = 1 )\n",
    "        axs[ii].set_xlabel(\"Predicted Value (scaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n(scaled)\")\n",
    "        axs[ii].set_title(nms[ii])\n",
    "        axs[ii].plot(Ytest_scaled[:,ii], Ytest_scaled[:,ii], 'b')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "fig.savefig(os.path.join(figDir, \"Keras_zerod.png\"), dpi = 120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(figDir, \"Keras_zerod.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_scaled = np.transpose(np.random.randn(1000))\n",
    "Ytrain_scaled = np.transpose(np.sin(Xtrain_scaled)+ np.random.randn(1000)*0.1)\n",
    "plt.scatter(Xtrain_scaled, Ytrain_scaled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=4, activation='relu', input_dim = 1000))\n",
    "model.add(Dense(1, activation='tanh'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain_scaled, Ytrain_scaled, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Generate dummy data\n",
    "Xtrain_scaled = np.random.randn(100000, 100).reshape((-1,100))*100\n",
    "Ytrain_scaled = np.sin(Xtrain_scaled[:,0]/50)*40+ np.random.randn(Xtrain_scaled.shape[0])*5\n",
    "Ytrain_scaled2 = np.cos(Xtrain_scaled[:,1]/100)+ np.random.randn(Xtrain_scaled.shape[0])*0.1\n",
    "\n",
    "Ytrain_scaled3 = np.transpose(np.vstack([Ytrain_scaled, Ytrain_scaled2]))\n",
    "print(Xtrain_scaled.shape)\n",
    "print(Ytrain_scaled3.shape)\n",
    "\n",
    "\n",
    "\n",
    "scalerX = StandardScaler()  \n",
    "scalerY = StandardScaler()  \n",
    "\n",
    "scalerX.fit(Xtrain_scaled)  \n",
    "scalerY.fit(Ytrain_scaled3) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain_scaled)  \n",
    "Ytrain_scaled4 = scalerY.transform(Ytrain_scaled3)  \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation = \"tanh\",  input_dim=Xtrain_scaled[:,0:2].shape[1]))\n",
    "model.add(Dense(100, activation = \"tanh\"))\n",
    "model.add(Dense(50, activation = \"tanh\"))\n",
    "model.add(Dense(500, activation = \"tanh\"))\n",
    "model.add(Dense(500, activation = \"tanh\"))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xtrain_scaled[:,0], Ytrain_scaled4[:,0])\n",
    "plt.scatter(Xtrain_scaled[:,1], Ytrain_scaled4[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(Xtrain_scaled[:,0:2], Ytrain_scaled4, epochs=1000, batch_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(Xtrain_scaled[:,0:2])\n",
    "plt.scatter(Xtrain_scaled[:,0], Ytrain_scaled4[:,0])\n",
    "plt.scatter(Xtrain_scaled[:,0], preds[:,0])\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(Xtrain_scaled[:,1], Ytrain_scaled4[:,1])\n",
    "plt.scatter(Xtrain_scaled[:,1], preds[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Ytrain_scaled4[:,1], preds[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation = \"tanh\",  input_dim=Xtrain_scaled.shape[1]))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(500))\n",
    "    model.add(Dense(500))\n",
    "    model.add(Dense(2))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=larger_model, epochs=100, batch_size=10000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=2, random_state=123)\n",
    "results = cross_val_score(estimator, Xtrain_scaled, Ytrain_scaled4, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(Xtrain_scaled, Ytrain_scaled4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = estimator.predict(Xtrain_scaled)\n",
    "plt.scatter(Xtrain_scaled[:,0], Ytrain_scaled4[:,0])\n",
    "plt.scatter(Xtrain_scaled[:,0], preds[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combDF.iloc[:, np.concatenate((np.arange(0,8), np.arange(792,800)))].copy()\n",
    "Y = combDF.iloc[:, [803, 805, 806]]\n",
    "\n",
    "# # subtract x_0 and y_0 from everything\n",
    "X.x_99 = X.x_99 - X.x_0\n",
    "X.y_99 = X.y_99 - X.y_0\n",
    "\n",
    "X.x_0 = X.y_0 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: scale test and training separately:\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scalerX = StandardScaler()  \n",
    "scalerY = StandardScaler()  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcheck = scalerX.inverse_transform(Xtrain_scaled)\n",
    "np.allclose(xcheck, np.array(Xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(dataDir, \"StandardScaler_zerod.pkl\"), 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([scalerX, scalerY], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del scalerX\n",
    "del scalerY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting back the objects:\n",
    "with open(os.path.join(dataDir, \"StandardScaler_zerod.pkl\"), 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    scalerX, scalerY = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check scaler\n",
    "plt.hist(Xtrain.iloc[:, 3])\n",
    "plt.show()\n",
    "plt.hist(Xtrain_scaled[:,3])\n",
    "plt.show()\n",
    "\n",
    "xcheck = scalerX.inverse_transform(Xtrain_scaled)\n",
    "plt.hist(xcheck[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain.shape,  Ytrain.shape, Xtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stt = time.time()\n",
    "# mor = MultiOutputRegressor(RandomForestRegressor(500, n_jobs = 4)).fit(Xtrain_scaled, Ytrain_scaled)\n",
    "# print(time.time() - stt) # ~ 13 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save RF model\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(mor, os.path.join(dataDir, \"FitRF_Scaled2.pkl\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpreds = mor.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close(\"all\")\n",
    "# fig, axs = plt.subplots(1,3, figsize=(15, 5), facecolor='w', edgecolor='k')\n",
    "# fig.subplots_adjust(hspace = 0.1, wspace=0.3)\n",
    "# fig.suptitle('Predicted vs. acutal for Mulit-output Random Forest Regressor (500 trees)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# axs = axs.ravel()\n",
    "# nms = [\"tao\", \"Fx\", \"Fy\"]\n",
    "\n",
    "\n",
    "# for ii in range(3):\n",
    "#     # read in image\n",
    "    \n",
    "#     try:\n",
    "#         axs[ii].scatter(y = Ytest_scaled[:,ii],x = mpreds[:,ii], s = 1, c= 'indianred' )\n",
    "#         axs[ii].set_xlabel(\"Predicted Value (Scaled)\")\n",
    "#         if(ii == 0):\n",
    "#             axs[ii].set_ylabel(\"Actual Value\\n(Scaled)\")\n",
    "#             axs[ii].set_xlim([-10, 5])\n",
    "#         axs[ii].set_title(nms[ii])\n",
    "#         axs[ii].plot(Ytest_scaled[:,ii], Ytest_scaled[:,ii], 'maroon')\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "    \n",
    "# fig.savefig(os.path.join(figDir, \"RFpreds_Scaled2.png\"), dpi = 120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-output neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt = time.time()\n",
    "nn1 = MLPRegressor(solver='lbfgs', alpha=0,\n",
    "                  hidden_layer_sizes=(100, 6), max_iter=10000, \n",
    "                  activation='tanh', verbose = True)\n",
    "nnMod = MultiOutputRegressor(nn1).fit(Xtrain_scaled, Ytrain_scaled)\n",
    "print(time.time() - stt) # takes 128 minutes on MBPro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save nn, so I can reload without retraining\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(nnMod, os.path.join(dataDir, \"TrainedNN_scaled_zerod.pkl\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nnMod = joblib.load(os.path.join(dataDir, \"TrainedNN_scaled_zerod.pkl\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpreds = nnMod.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,3, figsize=(15, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.3)\n",
    "fig.suptitle('Predicted vs. acutal for 2-hidden-layer Neural Network', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "\n",
    "for ii in range(3):\n",
    "    # read in image\n",
    "    \n",
    "    try:\n",
    "        axs[ii].scatter(y = Ytest_scaled[:,ii],x = nnpreds[:,ii], s = 1 )\n",
    "        axs[ii].set_xlabel(\"Predicted Value (scaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n(scaled)\")\n",
    "        axs[ii].set_title(nms[ii])\n",
    "        axs[ii].plot(Ytest_scaled[:,ii], Ytest_scaled[:,ii], 'b')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "fig.savefig(os.path.join(figDir, \"NNPreds2_zerod.png\"), dpi = 120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare simulation vs. nn preds for test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.concat([Xtest, Ytest], axis = 1).reset_index(drop = True)\n",
    "\n",
    "shuff2 = s1\n",
    "\n",
    "# predictions\n",
    "XX_scaled = scalerX.transform(shuff2.iloc[:, 0:16])\n",
    "nnpreds3 = nnMod.predict(XX_scaled)\n",
    "\n",
    "# add preds back to data frame\n",
    "nn_back = scalerY.inverse_transform(nnpreds3)\n",
    "preds1 = pd.DataFrame(nn_back)\n",
    "preds1.columns = [\"tao_pred\", \"Fx_pred\", \"Fy_pred\"]\n",
    "preds1[\"F_pred\"] = np.sqrt(preds1.Fx_pred **2 + preds1.Fy_pred **2)\n",
    "\n",
    "\n",
    "pre_alpha = np.arctan2(preds1.Fy_pred, preds1.Fx_pred )\n",
    "alpha = pre_alpha.copy()\n",
    "\n",
    "for ii in pre_alpha.index:\n",
    "    if (preds1.Fy_pred[ii] > 0) :\n",
    "        alpha[ii] = pre_alpha[ii]\n",
    "    else:\n",
    "        alpha[ii] = (2*np.pi) + pre_alpha[ii]\n",
    "        \n",
    "preds1[\"alpha_pred\"] = alpha\n",
    "\n",
    "\n",
    "preds1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_1 = pd.concat([shuff2, preds1], axis = 1)\n",
    "s2_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_1.to_csv(os.path.join(dataDir, \"simulationData5_withFinal_testset.csv\"), index=False)\n",
    "print(dataDir)\n",
    "\n",
    "simSet1 = s2_1.loc[:, ['x_0', 'y_0', 'theta_0', 'phi_0', 'x_dot_0', 'y_dot_0', 'theta_dot_0',\n",
    "       'phi_dot_0', 'tao_pred','F_pred','alpha_pred']]\n",
    "\n",
    "\n",
    "simSet1.to_csv(os.path.join(dataDir, \"simulationDataset5_blinded_testset.csv\"), index=False)\n",
    "simSet1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simSet1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: run simulation vs. nn preds for test set!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Create dataset with same initial conditions and shuffle output conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = combDF.iloc[:, np.hstack([np.arange(0,8),np.arange(792,800), [801, 802, 803]])].sample(1000, random_state = 1234)\n",
    "s1.reset_index(inplace = True)\n",
    "\n",
    "# set x_0 and y_0 to (0,0)  -- refref: may want to do this for training, actually\n",
    "s1.x_99 = s1.x_99 - s1.x_0\n",
    "s1.y_99 = s1.y_99 - s1.y_0\n",
    "\n",
    "s1.x_0 = 0\n",
    "s1.y_0 = 0\n",
    "\n",
    "s1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sTemp = s1.loc[:, ['x_99', 'y_99', 'theta_99', 'phi_99',\n",
    "       'x_dot_99', 'y_dot_99', 'theta_dot_99', 'phi_dot_99']]\n",
    "sInit = s1.loc[:, ['index', 'x_0', 'y_0', 'theta_0', 'phi_0', 'x_dot_0', 'y_dot_0',\n",
    "       'theta_dot_0', 'phi_dot_0']]\n",
    "\n",
    "shuff = sTemp.sample(sTemp.shape[0], random_state = 12346)\n",
    "shuff2 = pd.concat([sInit, shuff.reset_index(drop = True)], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "shuff2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "XX_scaled = scalerX.transform(shuff2.iloc[:, 1:17])\n",
    "nnpreds3 = nnMod.predict(XX_scaled)\n",
    "\n",
    "# add preds back to data frame\n",
    "nn_back = scalerY.inverse_transform(nnpreds3)\n",
    "preds1 = pd.DataFrame(nn_back)\n",
    "preds1.columns = [\"tao_pred\", \"Fx_pred\", \"Fy_pred\"]\n",
    "preds1[\"F_pred\"] = np.sqrt(preds1.Fx_pred **2 + preds1.Fy_pred **2)\n",
    "\n",
    "\n",
    "pre_alpha = np.arctan2(preds1.Fy_pred, preds1.Fx_pred )\n",
    "alpha = pre_alpha.copy()\n",
    "\n",
    "for ii in pre_alpha.index:\n",
    "    if (preds1.Fy_pred[ii] > 0) :\n",
    "        alpha[ii] = pre_alpha[ii]\n",
    "    else:\n",
    "        alpha[ii] = (2*np.pi) + pre_alpha[ii]\n",
    "        \n",
    "preds1[\"alpha_pred\"] = alpha\n",
    "\n",
    "\n",
    "preds1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_1 = pd.concat([shuff2, preds1], axis = 1)\n",
    "s2_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_1.to_csv(os.path.join(dataDir, \"simulationData4_withFinal.csv\"), index=False)\n",
    "print(dataDir)\n",
    "\n",
    "simSet1 = s2_1.loc[:, ['x_0', 'y_0', 'theta_0', 'phi_0', 'x_dot_0', 'y_dot_0', 'theta_dot_0',\n",
    "       'phi_dot_0', 'tao_pred','F_pred','alpha_pred']]\n",
    "\n",
    "\n",
    "simSet1.to_csv(os.path.join(dataDir, \"simulationDataset4_blinded.csv\"), index=False)\n",
    "simSet1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: might get better predictions if we set initial X and Y to (0,0) and\n",
    "# and transform output X and Y relative to the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Dataset to check in Jorge's simulation ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate dataset for Jorge to send to model\n",
    "s1 = combDF.iloc[:, np.hstack([np.arange(0,8),np.arange(792,800), [801, 802, 803]])].sample(1000)\n",
    "s1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "XX_scaled = scalerX.transform(s1.iloc[:, 0:16])\n",
    "nnpreds2 = nnMod.predict(XX_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.iloc[:, 0:16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[\"Fx\"] = s1.F * np.cos(s1.alpha)\n",
    "s1[\"Fy\"] = s1.F * np.sin(s1.alpha)\n",
    "s1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute F, alpha, to double check\n",
    "s1[\"F_\"] = np.sqrt(s1.Fx **2 + s1.Fy **2)\n",
    "\n",
    "\n",
    "pre_alpha = np.arctan2(s1.Fy, s1.Fx )\n",
    "alpha = pre_alpha.copy()\n",
    "\n",
    "for ii in pre_alpha.index:\n",
    "    if (s1.Fy[ii] > 0) :\n",
    "        alpha[ii] = pre_alpha[ii]\n",
    "    else:\n",
    "        alpha[ii] = (2*np.pi) + pre_alpha[ii]\n",
    "        \n",
    "s1[\"alpha_\"] = alpha\n",
    "s1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YY_scaled = scalerY.transform(s1.iloc[:, [18, 19, 20]])\n",
    "pd.DataFrame(YY_scaled).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to double-check\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,3, figsize=(15, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.3)\n",
    "fig.suptitle('Predicted vs. acutal for subset', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "# convert back to original values\n",
    "nn_back = scalerY.inverse_transform(nnpreds2)\n",
    "YY_orig = s1.iloc[:, [18, 19, 20]]\n",
    "\n",
    "\n",
    "for ii in range(3):\n",
    "    # read in image\n",
    "    \n",
    "    try:\n",
    "        axs[ii].scatter(y = YY_orig.iloc[:,ii],x = nn_back[:,ii], s = 1 )\n",
    "        axs[ii].set_xlabel(\"Predicted Value (scaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n(scaled)\")\n",
    "        axs[ii].set_title(nms[ii])\n",
    "        axs[ii].plot(nn_back[:,ii], nn_back[:,ii], 'b')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predictions to data frame\n",
    "preds1 = pd.DataFrame(nn_back)\n",
    "preds1.columns = [\"tao_pred\", \"Fx_pred\", \"Fy_pred\"]\n",
    "preds1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2 = pd.concat([s1.reset_index(drop=True), preds1.reset_index(drop=True)], axis = 1)\n",
    "cc2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2[\"F_pred\"] = np.sqrt(cc2.Fx_pred **2 + cc2.Fy_pred **2)\n",
    "\n",
    "\n",
    "pre_alpha = np.arctan2(cc2.Fy_pred, cc2.Fx_pred )\n",
    "alpha = pre_alpha.copy()\n",
    "\n",
    "for ii in pre_alpha.index:\n",
    "    if (cc2.Fy_pred[ii] > 0) :\n",
    "        alpha[ii] = pre_alpha[ii]\n",
    "    else:\n",
    "        alpha[ii] = (2*np.pi) + pre_alpha[ii]\n",
    "        \n",
    "cc2[\"alpha_pred\"] = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2.to_csv(os.path.join(dataDir, \"simulationData1_withFinal.csv\"), index=False)\n",
    "print(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simSet1 = cc2.loc[:, ['x_0', 'y_0', 'theta_0', 'phi_0', 'x_dot_0', 'y_dot_0', 'theta_dot_0',\n",
    "       'phi_dot_0', 'tao_pred','F_pred','alpha_pred']]\n",
    "simSet1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simSet1.to_csv(os.path.join(dataDir, \"simulationDataset1_blinded.csv\"), index=False)\n",
    "print(dataDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Dataset #2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now build another training dataset, that is random combinations of initial values\n",
    "\n",
    "def shuffle(df, n=1, axis=0):     \n",
    "    df = df.copy()\n",
    "    for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis=axis)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = combDF.iloc[:, np.hstack([np.arange(0,8),np.arange(792,800)])].sample(1500)\n",
    "ss.reset_index(drop = True, inplace = True)\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = shuffle(ss)\n",
    "s2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on shuffled data\n",
    "s2_scaled = scalerX.transform(s2)\n",
    "nnpreds3 = nnMod.predict(s2_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preds back to data frame\n",
    "nn_back = scalerY.inverse_transform(nnpreds3)\n",
    "preds1 = pd.DataFrame(nn_back)\n",
    "preds1.columns = [\"tao_pred\", \"Fx_pred\", \"Fy_pred\"]\n",
    "preds1[\"F_pred\"] = np.sqrt(preds1.Fx_pred **2 + preds1.Fy_pred **2)\n",
    "\n",
    "\n",
    "pre_alpha = np.arctan2(preds1.Fy_pred, preds1.Fx_pred )\n",
    "alpha = pre_alpha.copy()\n",
    "\n",
    "for ii in pre_alpha.index:\n",
    "    if (preds1.Fy_pred[ii] > 0) :\n",
    "        alpha[ii] = pre_alpha[ii]\n",
    "    else:\n",
    "        alpha[ii] = (2*np.pi) + pre_alpha[ii]\n",
    "        \n",
    "preds1[\"alpha_pred\"] = alpha\n",
    "\n",
    "\n",
    "preds1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_1 = pd.concat([s2, preds1], axis = 1)\n",
    "s2_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_1.to_csv(os.path.join(dataDir, \"simulationData2_withFinal.csv\"), index=False)\n",
    "\n",
    "simSet2 = s2_1.loc[:, ['x_0', 'y_0', 'theta_0', 'phi_0', 'x_dot_0', 'y_dot_0', 'theta_dot_0',\n",
    "       'phi_dot_0', 'tao_pred','F_pred','alpha_pred']]\n",
    "\n",
    "simSet2.to_csv(os.path.join(dataDir, \"simulationDataset2_blinded.csv\"), index=False)\n",
    "simSet2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ Dataset 3 -- Sample initial and get randomized final states \n",
    "\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = combDF.iloc[:, np.hstack([np.arange(0,8),np.arange(792,800)])].sample(1200)\n",
    "ss.reset_index(drop = True, inplace = True)\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only mix up possible output states\n",
    "s3_1 = shuffle(ss.iloc[:, 8:])\n",
    "s3_2 = pd.concat([ss.iloc[:,0:8], s3_1], axis = 1)\n",
    "s3_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on shuffled data\n",
    "s3_scaled = scalerX.transform(s3_2)\n",
    "nnpreds3_1 = nnMod.predict(s3_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preds back to data frame\n",
    "nn_back = scalerY.inverse_transform(nnpreds3_1)\n",
    "preds1 = pd.DataFrame(nn_back)\n",
    "preds1.columns = [\"tao_pred\", \"Fx_pred\", \"Fy_pred\"]\n",
    "preds1[\"F_pred\"] = np.sqrt(preds1.Fx_pred **2 + preds1.Fy_pred **2)\n",
    "\n",
    "\n",
    "pre_alpha = np.arctan2(preds1.Fy_pred, preds1.Fx_pred )\n",
    "alpha = pre_alpha.copy()\n",
    "\n",
    "for ii in pre_alpha.index:\n",
    "    if (preds1.Fy_pred[ii] > 0) :\n",
    "        alpha[ii] = pre_alpha[ii]\n",
    "    else:\n",
    "        alpha[ii] = (2*np.pi) + pre_alpha[ii]\n",
    "        \n",
    "preds1[\"alpha_pred\"] = alpha\n",
    "\n",
    "\n",
    "preds1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_4 = pd.concat([s3_2, preds1], axis = 1)\n",
    "s3_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_4.to_csv(os.path.join(dataDir, \"simulationData3_withFinal.csv\"), index=False)\n",
    "\n",
    "simSet3 = s3_4.loc[:, ['x_0', 'y_0', 'theta_0', 'phi_0', 'x_dot_0', 'y_dot_0', 'theta_dot_0',\n",
    "       'phi_dot_0', 'tao_pred','F_pred','alpha_pred']]\n",
    "\n",
    "simSet3.to_csv(os.path.join(dataDir, \"simulationDataset3_blinded.csv\"), index=False)\n",
    "simSet3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nn practice\n",
    "\n",
    "Xx = np.transpose(np.array([np.arange(-10, 10, step = 0.001), np.random.uniform(size = 20000)]))\n",
    "Xx_scaled = sklearn.preprocessing.scale(Xx, axis = 0)\n",
    "Yy = np.sin(Xx[:,0]) *4 **2 + 50\n",
    "Yy_scaled = sklearn.preprocessing.scale(Yy, axis = 0)\n",
    "plt.plot(Xx_scaled[:,0], Yy)\n",
    "plt.show()\n",
    "plt.scatter(Xx_scaled[:,1], Yy, s = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Xx_scaled[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt = time.time()\n",
    "nn1 = MLPRegressor(solver='lbfgs', alpha=0,\n",
    "                  hidden_layer_sizes=(10,10), max_iter=1000, \n",
    "                  verbose = True, tol=0.0000100,\n",
    "                  activation='tanh')\n",
    "nnMod = nn1.fit(Xx_scaled, Yy)\n",
    "print(time.time() - stt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpreds = nnMod.predict(Xx_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = Xx_scaled[:,0], y = Yy)\n",
    "plt.scatter(x = Xx_scaled[:,0], y = nnpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = Xx_scaled[:,0], y = Yy_scaled)\n",
    "plt.scatter(x = Xx_scaled[:,0], y = nnpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x = nnpreds, y = Yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with F, alpha, tao\n",
    "Vdta = Vmat[\"ValSp3\"]\n",
    "dd2 = pd.DataFrame(Vdta)\n",
    "dd2.columns = np.append([new_cols[ii] +\"_\" +str(99) for ii in range(8)], [\"F\", \"alpha\", \"tao\"])\n",
    "print(dd2.shape)\n",
    "dd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = dd\n",
    "\n",
    "\n",
    "stp = 8\n",
    "for stp in np.arange(10):\n",
    "    xx = 1\n",
    "    yy = 2\n",
    "    for ii in np.arange(1000):\n",
    "        plt.scatter(ff.iloc[stp*100:(stp+1)*100,xx], ff.iloc[stp*100:(stp+1)*100, yy], s = 1)\n",
    "        xx += 8\n",
    "        yy +=8\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 200\n",
    "\n",
    "for jj in np.arange(0, dta.shape[0], step = 8):\n",
    "    plt.scatter(dta[ii:ii+100, jj], dta[ii:ii+100, jj + 1], s = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\"x\", \"y\", \"theta\", \"phi\", \"x_dot\", \"y_dot\", \"theta_dot\", \"phi_dot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another possible way to rearrange the data\n",
    "ss = 8\n",
    "a = dta\n",
    "bb = np.array(np.zeros(a.shape)).reshape([-1, ss])\n",
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape[1]\n",
    "a.shape[0]\n",
    "pd.DataFrame(a[0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in np.arange(0, a.shape[1], step = a.shape[0]):\n",
    "    bb[kk:(kk+a.shape[0]),0:ss] = a[0:, kk:(ss+kk)]  \n",
    "\n",
    "    \n",
    "cc = pd.DataFrame(bb)\n",
    "cc.columns = new_cols\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.arange(0, 10000, step = 100):\n",
    "    plt.scatter(cc.loc[ii:ii+100, \"x\"],cc.loc[ii:ii+100, \"y\"], s = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2 = dta.reshape((-1, 8))\n",
    "dd3 = pd.DataFrame(dd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd3.columns =  [\"x\", \"y\", \"theta\", \"phi\", \"x_dot\", \"y_dot\", \"theta_dot\", \"phi_dot\"]\n",
    "dd3.head()\n",
    "\n",
    "plt.scatter(dd3.loc[1:10000, \"x\"],dd3.loc[1:10000, \"y\"], s = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [\"x\", \"y\", \"theta\", \"phi\", \"x_dot\", \"y_dot\", \"theta_dot\", \"phi_dot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialCond = dta[np.arange(0, dta.shape[0], step = 100),: ]\n",
    "finalCond = dta[np.arange(99, dta.shape[0], step = 100), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "i2 = initialCond.reshape((250000, 8))\n",
    "f2 = finalCond.reshape((250000, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(i2[2495:2555, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conddta = np.hstack((i2, f2))\n",
    "condDta2 = pd.DataFrame(conddta)\n",
    "condDta2.columns = np.concatenate(([ii + \"_i\" for ii in new_cols], [ii + \"\" for ii in new_cols]))\n",
    "print(condDta2.shape)\n",
    "condDta2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vmat = scipy.io.loadmat(os.path.join(dataDir, \"ValSp3_1_am_con.mat\"))\n",
    "Vmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this might work\n",
    "forceAngle = np.transpose(Vmat[\"ValSp3\"])\n",
    "fa = forceAngle.reshape((250000, 12), order = \"C\" )\n",
    "fa2=  pd.DataFrame(fa)\n",
    "fa2.columns = np.concatenate((new_cols, [\"F\", \"alpha\", \"tao\", \"cost\"]))\n",
    "fa2[\"Fx\"] = fa2.F * np.cos(fa2.alpha)\n",
    "fa2[\"Fy\"] = fa2.F * np.sin(fa2.alpha)\n",
    "fa2\n",
    "combDF = pd.merge(condDta2.dropna(), fa2.dropna(), left_on = new_cols, right_on = new_cols, how = \"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combDF.dropna().iloc[:, 0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA's\n",
    "X = np.array(combDF.dropna().iloc[:, 0:16])\n",
    "Y = np.array(combDF.dropna().iloc[:, [18, 20, 21]])\n",
    "\n",
    "# check: refref: not checked\n",
    "print(all(X[:,9] == Y[:,1]))\n",
    "print(len(X))\n",
    "\n",
    "#Y = Y[:, [10, 12, 13]]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mor = MultiOutputRegressor(RandomForestRegressor(1000, n_jobs = 4)).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpreds = mor.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nms = [\"tao\", \"Fx\", \"Fy\"]\n",
    "\n",
    "for ii in range(3):\n",
    "    plt.scatter(y = Ytest[:,ii],x = mpreds[:,ii], s = 2 )\n",
    "    plt.xlabel(\"Predicted Value\")\n",
    "    plt.ylabel(\"Actual Value\")\n",
    "    plt.title(nms[ii])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.vstack((np.arange(8), np.arange(7, 15), np.arange(7, 15)))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 2\n",
    "bb = np.array(np.zeros(a.shape)).reshape([-1, ss])\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, a.shape[1], step = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 2\n",
    "\n",
    "for kk in np.arange(0, a.shape[1], step = a.shape[0]):\n",
    "    bb[kk:(kk+a.shape[0]),0:ss] = a[0:, kk:(ss+kk)]  \n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb[kk:(kk+ss),0:ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss =2\n",
    "kk = 2\n",
    "\n",
    "a[0:, kk:(ss+kk)]\n",
    "bb[kk:(kk+a.shape[0]),0:ss]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: figure out how to reshape this\n",
    "\n",
    "a.reshape((-1, 2), order = \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame(fa)\n",
    "print(dd.shape)\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = dd.transpose()\n",
    "fa.columns = np.concatenate((new_cols, [\"F\", \"alpha\", \"tao\", \"cost\"]))\n",
    "print(fa.shape)\n",
    "fa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Fx and Fy\n",
    "fa[\"Fx\"] = fa.F * np.cos(fa.alpha)\n",
    "fa[\"Fy\"] = fa.F * np.sin(fa.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.arange(1, spray.shape[1], step = 8):\n",
    "\n",
    "    tmparr = np.hstack((sparray[0, ii:ii+8], sparray[99, ii:ii+8]))\n",
    "\n",
    "    if ii == 1:\n",
    "        newArr = tmparr\n",
    "    else: \n",
    "        newArr = np.vstack((newArr, tmparr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = pd.DataFrame(newArr)\n",
    "newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF.columns = np.concatenate(([ii + \"_i\" for ii in new_cols], [ii + \"\" for ii in new_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newDF.shape)\n",
    "newDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA's\n",
    "X = np.array(newDF.dropna())\n",
    "Y = np.array(fa.dropna())\n",
    "\n",
    "# check\n",
    "print(all(X[:,9] == Y[:,1]))\n",
    "print(len(X))\n",
    "\n",
    "Y = Y[:, [10, 12, 13]]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0:10, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combDF = pd.merge(newDF.dropna(), fa.dropna(), left_on = new_cols, right_on = new_cols, how = \"inner\")\n",
    "print(combDF.shape)\n",
    "combDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test and training set\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf1 = RandomForestRegressor(1000, n_jobs = 4).fit(Xtrain, Ytrain)\n",
    "Ypred1 = clf1.predict(Xtest)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(Ypred1[:, 0], Ypred1[:, 1], 'o', alpha=0.5)\n",
    "ax.set_xlabel('$y_1$'); ax.set_ylabel('$y_2$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(3):\n",
    "    plt.scatter(Ytest[:,ii],Ypred1[:,ii] )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputRF(object):\n",
    "    \n",
    "    '''From here: http://astrohackweek.org/blog/multi-output-random-forests.html'''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        X, Y = map(np.atleast_2d, (X, Y))\n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "        Ny = Y.shape[1]\n",
    "        \n",
    "        self.clfs = []\n",
    "        for i in range(Ny):\n",
    "            clf = RandomForestRegressor(*self.args, **self.kwargs)\n",
    "            Xi = np.hstack([X, Y[:, :i]])\n",
    "            yi = Y[:, i]\n",
    "            self.clfs.append(clf.fit(Xi, yi))\n",
    "            \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        Y = np.empty([X.shape[0], len(self.clfs)])\n",
    "        for i, clf in enumerate(self.clfs):\n",
    "            Y[:, i] = clf.predict(np.hstack([X, Y[:, :i]]))\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = MultiOutputRF(1000, n_jobs = 4).fit(Xtrain, Ytrain)\n",
    "Ypred2 = clf2.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: might want to break down into Fx and Fy, b/c radians don't work well with MSE\n",
    "\n",
    "nms = [\"tao\", \"Fx\", \"Fy\"]\n",
    "\n",
    "for ii in range(3):\n",
    "    plt.scatter(y = Ytest[:,ii],x = Ypred2[:,ii], s = 2 )\n",
    "    plt.xlabel(\"Predicted Value\")\n",
    "    plt.ylabel(\"Actual Value\")\n",
    "    plt.title(nms[ii])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works surprisingly well\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "mor = MultiOutputRegressor(RandomForestRegressor(1000, n_jobs = 4)).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpreds = mor.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = [\"tao\", \"Fx\", \"Fy\"]\n",
    "\n",
    "for ii in range(3):\n",
    "    plt.scatter(y = Ytest[:,ii],x = mpreds[:,ii], s = 2 )\n",
    "    plt.xlabel(\"Predicted Value\")\n",
    "    plt.ylabel(\"Actual Value\")\n",
    "    plt.title(nms[ii])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residuals\n",
    "nms = [\"tao\", \"Fx\", \"Fy\"]\n",
    "\n",
    "for ii in range(3):\n",
    "    plt.scatter(y = Ytest[:,ii]- mpreds[:,ii], x = np.arange(len(Ytest[:,ii])), s = 2 )\n",
    "    plt.xlabel(\"Predicted Value\")\n",
    "    plt.ylabel(\"Actual Value\")\n",
    "    plt.title(nms[ii])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: next step -- neural network\n",
    "#from sklearn import cross_validation\n",
    "#from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#model = MLPRegressor(solver='lbfgs',alpha=0.001,hidden_layer_sizes=(150,)) \n",
    "#cross_validation.cross_val_score(model, X, Y, scoring='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another possible way to rearrange the data\n",
    "ss = 12\n",
    "a = np.transpose(Vmat[\"ValSp3\"])\n",
    "bb = np.array(np.zeros(a.shape)).reshape([-1, ss])\n",
    "bb\n",
    "\n",
    "for kk in np.arange(0, a.shape[1], step = a.shape[0]):\n",
    "    bb[kk:(kk+a.shape[0]),0:ss] = a[0:, kk:(ss+kk)]  \n",
    "\n",
    "    \n",
    "forceAngle = pd.DataFrame(bb)\n",
    "forceAngle.columns = np.concatenate((new_cols, [\"F\", \"alpha\", \"tao\", \"cost\"]))\n",
    "forceAngle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
