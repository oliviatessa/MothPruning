{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 30 May 2019\n",
    "### eScience Community Seminar Prep\n",
    "\n",
    "\n",
    "# Make videos of tracking moth"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Outline:\n",
    "** show how well moth can follow trajectory with network\n",
    "** make function to predict with nnet and then evaluate immediately with ODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
      "last run on 2019-06-11 11:01:22.354893\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.patches import Arc\n",
    "from collections import OrderedDict\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import pandas as pd\n",
    "import importlib\n",
    "print(sys.version)\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.36.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba\n",
    "numba.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simUtils_twoTorque_DLVersion as simUtils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'simUtils_twoTorque_DLVersion' from 'C:\\\\Users\\\\calli\\\\Documents\\\\GitRepos\\\\MothMachineLearning\\\\simUtils_twoTorque_DLVersion.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(simUtils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "tensorflow using CPU\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-06-11 11:01:29.573532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as colors\n",
    "from  mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "\n",
    "# make sure Keras uses CPU instead of GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "else: \n",
    "    print(\"tensorflow using CPU\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "randomRawData = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\PythonGeneratedData\\TrainingData'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def pol2cart(rho, phi):\n",
    "    '''\n",
    "    rho: radius\n",
    "    phi: angle (in radians)\n",
    "    '''\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return ((p1[0]+p2[0])/2, (p1[1]+p2[1])/2)\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.000001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 30,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.02, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0001, 0.0, 0.0001, 3.141592653589793, 0.0001, 0.0, 0.0001]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "state0_ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 0\n",
    "alpha = np.pi/2\n",
    "tau0 = 20\n",
    "tau_w = 2001\n",
    "\n",
    "FAlphaTau_list = [F, alpha, tau0, tau_w]\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>xd</th>\n",
       "      <th>y</th>\n",
       "      <th>yd</th>\n",
       "      <th>theta</th>\n",
       "      <th>thetad</th>\n",
       "      <th>phi</th>\n",
       "      <th>phid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.375258e-09</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.159193</td>\n",
       "      <td>3.142068</td>\n",
       "      <td>1.343692</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>1.277065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.497974e-07</td>\n",
       "      <td>-0.002975</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.282848</td>\n",
       "      <td>3.143446</td>\n",
       "      <td>2.650594</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>2.583967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.132408e-06</td>\n",
       "      <td>-0.010061</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.406487</td>\n",
       "      <td>3.145724</td>\n",
       "      <td>3.957495</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>3.890868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.634247e-05</td>\n",
       "      <td>-0.023729</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.530077</td>\n",
       "      <td>3.148904</td>\n",
       "      <td>5.264396</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>5.197769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x        xd         y        yd     theta    thetad       phi  \\\n",
       "0  0.000000e+00  0.000100  0.000000  0.000100  3.141593  0.000100  0.000000   \n",
       "1 -4.375258e-09 -0.000309  0.000067  0.159193  3.142068  1.343692  0.000430   \n",
       "2 -9.497974e-07 -0.002975  0.000219  0.282848  3.143446  2.650594  0.001762   \n",
       "3 -5.132408e-06 -0.010061  0.000457  0.406487  3.145724  3.957495  0.003994   \n",
       "4 -1.634247e-05 -0.023729  0.000780  0.530077  3.148904  5.264396  0.007128   \n",
       "\n",
       "       phid  \n",
       "0  0.000100  \n",
       "1  1.277065  \n",
       "2  2.583967  \n",
       "3  3.890868  \n",
       "4  5.197769  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tragDF = pd.DataFrame([x, xd, y, yd, theta, thetad, phi, phid]).transpose()\n",
    "tragDF.columns = \"x, xd, y, yd, theta, thetad, phi, phid\".split(\", \")\n",
    "tragDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d6393cfcf8>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d637d1edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tragDF.plot(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot moth at certain timesteps\n",
    "# plot final positions\n",
    "def plotMoth(x,y,theta, phi, F, alpha, tau0, fig, ax):\n",
    "    # plot moth and force\n",
    "\n",
    "    thoraxLen = 0.908 * 2# cm\n",
    "    abLen = 1.747 *2 #cm\n",
    "    bodyWidth = 1.1\n",
    "\n",
    "\n",
    "    # plot trajectory\n",
    "    #fig, ax = plt.subplots( figsize = [10,10])\n",
    "    ax.set_aspect('equal', 'datalim')\n",
    "    #ax.plot(x,y, label = 'trajectory x vs y')\n",
    "\n",
    "    center = np.array([x, y])\n",
    "    head = center + np.array(pol2cart(thoraxLen, theta))\n",
    "    abTip = center + np.array(pol2cart(abLen, phi))\n",
    "\n",
    "\n",
    "\n",
    "    xx, yy = zip(*[center, head])\n",
    "    xab,yab = zip(*[center, abTip])\n",
    "\n",
    "    el = Ellipse(midpoint(center, head), width = thoraxLen, height = bodyWidth, facecolor='#907760', alpha=0.9, angle = math.degrees(theta))\n",
    "    el2 = Ellipse(midpoint(center, abTip), width = abLen, height = bodyWidth, facecolor='#DEC9B0', alpha=0.9, angle = math.degrees(phi))\n",
    "    \n",
    "#     torqueArc = Arc([x,y], 1, 1, angle=0.0, theta1= np.degrees(theta), theta2=np.degrees(phi), color = \"#B61212\")\n",
    "    \n",
    "    \n",
    "    ax.add_artist(el)\n",
    "    ax.add_artist(el2)\n",
    "#     ax.add_artist(torqueArc)\n",
    "    \n",
    "#     # add torque arrow\n",
    "#     ax.arrow(x = x + 1, y = forceCenter[1], \n",
    "#              dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "#             head_width = 0.2, color = \"#B61212\")\n",
    "\n",
    "\n",
    "\n",
    "    ax.plot(xx, yy, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xx, yy, s= 10, c = 'k', alpha = 0.2)\n",
    "    ax.plot(xab,yab, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xab,yab, s = 10, c = 'k', alpha = 0.2)\n",
    "\n",
    "    # plot force \n",
    "    forceAlpha = alpha\n",
    "    forceCenter = midpoint(center, head)\n",
    "    forceMagnitude = F / 15000 # scale \n",
    "    forceAngle = theta + forceAlpha\n",
    "    forceTip = np.add(pol2cart(forceMagnitude, forceAngle), forceCenter)\n",
    "    ax.arrow(x = forceCenter[0], y = forceCenter[1], \n",
    "             dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "            head_width = 0.2, color = \"#B61212\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tmp dir for images\n",
    "tmpDir2 = os.path.join(r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs', \"MothVid_twoTorque\")\n",
    "if not os.path.exists(tmpDir2):\n",
    "    os.mkdir(tmpDir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize = [10,10])\n",
    "# plt.axes().set_aspect('equal', 'datalim')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "maxFrms = len(x)\n",
    "\n",
    "xlim = [np.min(x[0:maxFrms+1])-5, np.max(x[0:maxFrms+1])+5]\n",
    "ylim =[np.min(y[0:maxFrms+1])-5, np.max(y[0:maxFrms+1])+5]\n",
    "xrng = np.diff(xlim)\n",
    "yrng = np.diff(ylim)\n",
    "maxrng = np.max([xrng, yrng])\n",
    "newxlim = [np.sum(xlim)/2 - maxrng /2, np.sum(xlim)/2 + maxrng /2]\n",
    "newylim = [np.sum(ylim)/2 - maxrng /2, np.sum(ylim)/2 + maxrng /2 ]\n",
    "\n",
    "\n",
    "for ii in np.arange(1, maxFrms, 1):\n",
    "    fig, ax = plt.subplots( figsize = [10,10])\n",
    "\n",
    "    plt.plot(x[0:ii+1], y[0:ii+1], c= 'orange', label = \"Python\")\n",
    "    plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "    \n",
    "\n",
    "    ax.set_ylim(newylim)\n",
    "    ax.set_xlim(newxlim)\n",
    "    ax.set_ylabel(\"vertical position (cm)\")\n",
    "    ax.set_xlabel(\"horizontal position (cm)\")\n",
    "    \n",
    "#     # add torque\n",
    "#     if tau0 < 0:\n",
    "#         marker = r'$\\circlearrowleft$'\n",
    "#     else:\n",
    "#         marker = r'$\\circlearrowright$'\n",
    "#     ax.plot(x[ii],y[ii], marker=marker,ms=tau0/100000,  color = \"#B61212\")\n",
    "    fig.savefig(os.path.join(tmpDir2, str(ii).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "    # plt.legend()\n",
    "    plt.close()\n",
    "    if np.mod(ii, 10) == 0:\n",
    "        print(ii)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir2)\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 30 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000001_output_mothPath2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model and scaler\n",
    "modelPath = r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0__Num_512_512_512_16__Wei_0_2019_06_11__11_27_06_fullActuated.h5\"\n",
    "model = load_model(modelPath)\n",
    "\n",
    "# read in scalers\n",
    "scalerX = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput_twoTorque\\scalerX_fullact.pkl\", \"rb\"))\n",
    "scalerY = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput_twoTorque\\scalerY_fullact.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               5632      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 539,288\n",
      "Trainable params: 539,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REFREF: check model loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate F and alpha from Fx and Fy\n",
    "\n",
    "# calculate alpha\n",
    "def quadrant(Fx, Fy):\n",
    "    if (Fx >= 0) & (Fy >= 0):\n",
    "        q = 1\n",
    "    elif (Fx < 0) & (Fy >= 0):\n",
    "        q = 2\n",
    "    elif (Fx < 0) & (Fy < 0):\n",
    "        q = 3\n",
    "    elif (Fx >= 0) & (Fy < 0):\n",
    "        q = 4\n",
    "    else:\n",
    "        q = 999999\n",
    "    return(q)\n",
    "\n",
    "\n",
    "def angleCalc(Fx, Fy, q):\n",
    "    fx = np.abs(Fx)\n",
    "    fy = np.abs(Fy)\n",
    "    \n",
    "    if q == 1:\n",
    "        alpha = np.arctan(fy/fx)\n",
    "    elif q == 2:\n",
    "        alpha = np.pi - np.arctan(fy/fx)\n",
    "    elif q == 3: \n",
    "        alpha = np.pi + np.arctan(fy/fx)\n",
    "    elif q == 4:\n",
    "        alpha = (2*np.pi) - np.arctan(fy/fx)\n",
    "    return(alpha)\n",
    "\n",
    "def F_alpha_calc (Fx, Fy):\n",
    "    q = quadrant(Fx, Fy)\n",
    "    alpha = angleCalc(Fx, Fy, q)\n",
    "    F = np.sqrt(Fx**2 + Fy**2)\n",
    "    return(F, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputData = # make dataset\n",
    "Xcols = [ \"phi_0\", \"theta_0\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\",\n",
    "                   \"x_99\", \"y_99\", \n",
    "                    \"phi_99\", \"theta_99\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: this might be wrong. \n",
    "\n",
    "goalPositions = {\"x_0\": [0], \n",
    "                 \"x_dot_0\":[-0.0001], # should this be x_dot_99?\n",
    "                 \"y_0\":[0], \n",
    "                 \"y_dot_0\": [0.0001]  ,\n",
    "                 \"theta_0\": [np.pi]  ,\n",
    "                 \"theta_dot_0\": [0.0001]  , \n",
    "                 \"phi_0\": [0]   ,\n",
    "                 \"phi_dot_0\":[0.0001] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phi_0   theta_0  x_dot_0  y_dot_0  phi_dot_0  theta_dot_0  x_99  y_99  \\\n",
       "0      0  3.141593  -0.0001   0.0001     0.0001       0.0001     0     0   \n",
       "\n",
       "   phi_99  theta_99  \n",
       "0       0       0.0  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goalDF = pd.DataFrame(goalPositions)\n",
    "\n",
    "\n",
    "goalDF[\"x_99\"] = np.hstack([goalDF.loc[1:, \"x_0\"], 0])\n",
    "goalDF[\"y_99\"] = np.hstack([goalDF.loc[1:, \"y_0\"], 0])\n",
    "goalDF[\"phi_99\"] = np.hstack([goalDF.loc[1:, \"phi_0\"], 0])\n",
    "goalDF[\"theta_99\"] = np.hstack([goalDF.loc[1:, \"theta_0\"], 0])\n",
    "goalDF_ordered = goalDF.loc[ :, Xcols]\n",
    "goalDF_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref calculate new x and y from error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0001, 0.0, 0.0001, 3.141592653589793, 0.0001, 0.0, 0.0001]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make video with pred\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = goalDF_ordered.iloc[0, ]\n",
    "state0_ICs\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "state0_ICs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "overallCtr = 1\n",
    "\n",
    "\n",
    "# refref: maybe the derivatives should be in the input, so it doesn't go too fast\n",
    "\n",
    "# define initial position and goal position\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "where_I_am = OrderedDict({\n",
    "                        \"x_0\": [0], \n",
    "                        \"x_dot_0\":[-0.0001], \n",
    "                        \"y_0\":[0], \n",
    "                        \"y_dot_0\": [0.0001]  ,\n",
    "                        \"theta_0\": [np.pi/2]  ,\n",
    "                        \"theta_dot_0\": [0.0001]  , \n",
    "                        \"phi_0\": [3*np.pi/2]   ,\n",
    "                        \"phi_dot_0\":[0.0001] })\n",
    "\n",
    "\n",
    "where_I_want2b = OrderedDict({\"x_99\": [0],\n",
    "                              \"y_99\": [0],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2]})\n",
    "\n",
    "xList = []\n",
    "yList = []\n",
    "\n",
    "prevXY = [where_I_am[\"x_0\"][0], where_I_am[\"y_0\"][0]]\n",
    "\n",
    "goalXY = [where_I_want2b[\"x_99\"][0], where_I_want2b[\"y_99\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d636493358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "# don't pay attention to F, alpha, tau0\n",
    "plotMoth(where_I_am[\"x_0\"][0],where_I_am[\"y_0\"][0],where_I_am[\"theta_0\"][0], where_I_am[\"phi_0\"][0], F, alpha, tau0, fig, ax)\n",
    "plotMoth(where_I_want2b[\"x_99\"][0],\n",
    "         where_I_want2b[\"y_99\"][0],\n",
    "         where_I_want2b[\"theta_99\"][0],\n",
    "         where_I_want2b[\"phi_99\"][0], F, alpha, tau0, fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData =  pd.DataFrame(OrderedDict(list(where_I_am.items()) + list(where_I_want2b.items())))\n",
    "inputData = inputData.loc[:, Xcols]\n",
    "#print(inputData)\n",
    "\n",
    "# read in scalers\n",
    "scalerX = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput_twoTorque\\scalerX_fullact.pkl\", \"rb\"))\n",
    "scalerY = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput_twoTorque\\scalerY_fullact.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   949.33703613,   4921.85302734, -54619.19921875,   2125.46362305,\n",
       "         -316.20004272,   -144.88017273,    -77.69651031,    -87.6317749 ], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict force needed to attain \n",
    "## scale data and transform\n",
    "X_scaled = scalerX.transform(inputData)\n",
    "\n",
    "\n",
    "## predict with nnet\n",
    "pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "# inverse transform\n",
    "pred_trans = scalerY.inverse_transform(pred)\n",
    "\n",
    "pred_trans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\AcademiaDropbox\\\\mothMachineLearning_dataAndFigs\\\\Figs\\\\MothVid_twoTorque'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpDir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 0\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 1\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 2\n"
     ]
    }
   ],
   "source": [
    "###### start of loop\n",
    "for jj in range(3):\n",
    "\n",
    "    inputData =  pd.DataFrame(OrderedDict(list(where_I_am.items()) + list(where_I_want2b.items())))\n",
    "    inputData = inputData.loc[:, Xcols]\n",
    "\n",
    "\n",
    "    # predict force needed to attain \n",
    "    ## scale data and transform\n",
    "    X_scaled = scalerX.transform(inputData)\n",
    "    \n",
    "    \n",
    "    ## predict with nnet\n",
    "    pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "    # inverse transform\n",
    "    pred_trans = scalerY.inverse_transform(pred)\n",
    "    Fx, Fy, tau0, tau_w, x_dot_99, y_dot_99, phi_dot_99, theta_dot_99  = pred_trans[0]\n",
    "\n",
    "    # convert FX, Fy, back to F, alpha\n",
    "    # F, alpha = cart2pol(Fx, Fy)\n",
    "    F, alpha = F_alpha_calc(Fx, Fy)\n",
    "\n",
    "\n",
    "    # plug predictions into simulation\n",
    "    FAlphaTau_list = [F, alpha, tau0, tau_w]\n",
    "\n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    state0_ICs = [ v[0] for v in where_I_am.values() ]\n",
    "\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    # add previous position to x and y\n",
    "    x = x + prevXY[0]\n",
    "    y = y + prevXY[1]\n",
    "    \n",
    "    # plot actual position\n",
    "    xList.extend(x.tolist())\n",
    "    yList.extend(y.tolist())\n",
    "\n",
    "\n",
    "\n",
    "    maxFrms = len(x)\n",
    "\n",
    "\n",
    "\n",
    "    # refref: add x's to each plot\n",
    "    for ii in np.arange(0, maxFrms, 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.plot(xList[:-(maxFrms-ii)], yList[:-(maxFrms-ii)], c= 'orange', label = \"moth trajectory\", alpha = 0.3)\n",
    "        #plt.plot(where_I_want2b[\"x_99\"], where_I_want2b[\"y_99\"], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plt.plot(goalXY[0], goalXY[1], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "#         ax.set_ylim([-30, 30])\n",
    "#         ax.set_xlim([-30, 30])\n",
    "        ax.set_ylim([-80, 80])\n",
    "        ax.set_xlim([-80, 80])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir2, str(overallCtr).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        #plt.show()\n",
    "        overallCtr += 1\n",
    "\n",
    "\n",
    "        plt.close()\n",
    "        if np.mod(ii, 3) == 0:\n",
    "            print(ii)\n",
    "\n",
    "\n",
    "\n",
    "    # calculate error and compute new initial position, but keep goal position the same\n",
    "\n",
    "    ### REFREF: may be calculating this incorrectly\n",
    "    ### where I am should always start at x_0, y_0 == (0, 0)\n",
    "    ### where I want to be should be the error....\n",
    "    \n",
    "    # update prevXY\n",
    "    prevXY = [x[-1], y[-1]]\n",
    "    \n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    where_I_am2 = OrderedDict({\n",
    "                            \"x_0\": [0], \n",
    "                            \"x_dot_0\":[xd[-1]], \n",
    "                            \"y_0\":[0], \n",
    "                            \"y_dot_0\": [yd[-1]]  ,\n",
    "                            \"theta_0\": [theta[-1]]  ,\n",
    "                            \"theta_dot_0\": [thetad[-1]] , \n",
    "                            \"phi_0\": [phi[-1]]   ,\n",
    "                            \"phi_dot_0\":[phid[-1]] })\n",
    "\n",
    "\n",
    "    # calculate true position\n",
    "    actual_whereIam = OrderedDict({\n",
    "                            \"x\": [where_I_want2b[\"x_99\"] + x],\n",
    "                            \"y\":[where_I_want2b[\"x_99\"] + y]})\n",
    "    \n",
    "    where_I_want2b2 = OrderedDict({\"x_99\": [ goalXY[0] - prevXY[0] ],\n",
    "                              \"y_99\": [goalXY[1] - prevXY[1]],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2]})\n",
    "    \n",
    "    # update whereIam\n",
    "    where_I_am = where_I_am2\n",
    "    where_I_want2b = where_I_want2b2\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"loop\", jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir2)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 60 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_output_mothPath_45deg.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goalXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_want2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: do the same thing with a smaller, pruned network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make vid of multiple moth trajectoies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 40,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.1, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug predictions into simulation\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, alpha, tau0 = (np.random.rand(3)* 1000).tolist()\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi/2 - 0.3,0.0001, -np.pi/2 - 0.3,0.0001]\n",
    "state0_ICs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDir3 = os.path.join(r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019', \"MPC_Example\")\n",
    "if not os.path.exists(tmpDir3):\n",
    "    os.mkdir(tmpDir3)\n",
    "\n",
    "overallCtr2 = 1\n",
    "\n",
    "\n",
    "xlist = []\n",
    "ylist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pathNum in range(20):\n",
    "    F, alpha, tau0 = (np.random.rand(3)* 10000).tolist()\n",
    "    tau0 = tau0*10\n",
    "    FAlphaTau_list = [F, alpha, tau0]\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    xlist.extend(x)\n",
    "    ylist.extend(y)\n",
    "\n",
    "\n",
    "    for ii in np.arange(0, globalDict[\"nstep\"], 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.scatter(xlist[:-(globalDict[\"nstep\"]-ii-1)], ylist[:-(globalDict[\"nstep\"]-ii-1)], c= 'orange', label = \"moth trajectory\", s = 2)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "        ax.set_ylim([-30, 30])\n",
    "        ax.set_xlim([-30, 30])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir3, str(overallCtr2).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        overallCtr2 += 1\n",
    "\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir3)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 30 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2, setpts=0.2*PTS\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_MPCVID.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0\n",
    "xlist[:-(globalDict[\"nstep\"]-ii-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(randomRawData, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: check for repeats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=150, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: start with small network and then build up\n",
    "# refref: start with large network and prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [32, 32, 32, 32], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "\n",
    "# model = load_model(r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0.0__Num_400_400_400_16__Wei_0.0.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [400, 400, 400, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show random weight matrices\n",
    "# show images for matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-5:256//2+5, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RandomWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=15, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1000, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDict[\"mean_squared_error\"].extend(history.history[\"mean_squared_error\"][0:])\n",
    "historyDict[\"val_mean_squared_error\"].extend(history.history[\"val_mean_squared_error\"][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_NOTpruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "# if I need to remake, use this\n",
    "# wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "# wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"TrainedWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refref: plot predictions on test set and make figures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "# apply same transformation to test data\n",
    "# Xtest_scaled = scalerX.transform(Xtest)\n",
    "# Ytest_scaled = scalerY.transform(Ytest)\n",
    "\n",
    "\n",
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "\n",
    "# make data frames\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_c = df_c[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_notPruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(7):\n",
    "    print (r2_score(df_c.iloc[:,jj ],  df_c.iloc[:,jj+7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START NEW ITEM: train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "#wts =  pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start training\n",
    "# historyDict = {\"mean_squared_error\": [], \n",
    "#                \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start pruning\n",
    "modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numCuts)\n",
    "(50 - cutPercent[numCuts]) * 2 # percent of original network size that is used the pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_Pruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts_pruned.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history_pruned.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numCuts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dictLen).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "#for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "for dictLen in range(300):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(historyDict['mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.plot(range(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "#for dictLen in np.arange(1, 100):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir)\n",
    "\n",
    "os.system('ffmpeg -start_number 0   -r 50 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264 -b:v 10000k  -pix_fmt yuv420p -y  0000000_output_epochs.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frames\n",
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historyDict[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.iloc[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + str(len(historyDict[\"mean_squared_error\"])) +  modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2+1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"Pruned_WeightMatrices\" + str(len(historyDict[\"mean_squared_error\"]))  + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example small network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [20, 20, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])   \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "              \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RondomWTS_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ii in range(100):\n",
    "    \n",
    "        # # fit model without regularization\n",
    "    stt = time.time()\n",
    "    history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                            batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "    winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "    endd = time.time() - stt\n",
    "    print(endd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "    ctr += 1\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWeightImages(model):\n",
    "    \n",
    "     wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWts_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good can I get without trimming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "for ii in np.arange(0, len(wts), 2):\n",
    "    plt.matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot biases\n",
    "\n",
    "for ii in np.arange(1, len(wts), 2):\n",
    "    plt.matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save weights and model\n",
    "model.save(os.path.join(savedModels,  modelName + '_pruned_bias.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_pruned_wts_bias.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,5, figsize=(20, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.2)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "    \n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(5,1, figsize=(30, 10), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(1, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=(30, 10), facecolor='w', edgecolor='k', )\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.1)\n",
    "\n",
    "\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWeightMatrices.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: if whole node is basically 0, then remove the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(wts[2].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(**modelParams)\n",
    "\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model_400Units_newData.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "cutPercent = 49.7\n",
    "for numCuts in range(3):\n",
    "    for numEpocs in range(100):\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 2):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent, 50 + cutPercent), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_and_ODE",
   "language": "python",
   "name": "dl_and_ode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
